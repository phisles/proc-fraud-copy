{
    "filename": "docNAC01FB7453538227bb1538cecadff4b852a42eba06482e77570ea14509a56354333e7bc307ef.pdf",
    "text_by_page": {
        "2": "Small Business Innovation Research(SBIR) Program - Proposal Cover Sheet Disclaimer Knowingly and willfully making any false, fictitious, or fraudulent statements or representations may be a felony under the Federal Criminal False Statement Act (18 USC Sec 1001), punishable by a fine of up to $10,000, up to five years in prison, or both.\nSBIR Phase I Proposal Proposal Number: F244-0001-0094 Proposal Faster, Easier, and More Accurate Automated Updating of Dynamic Knowledge Title: Graphs for Intelligence and Operations Using Graph Attention Networks and Update Impact Prediction Networks Agency Information Agency Name: Command: USAF AFMC Topic Number: AF244-0001 Firm Information Firm Name: Cenith Innovations, LLC Address: Website: UEI: DUNS: CAGE: 1861 9th Avenue, Sacramento, CA 95818-4111 http://www.cenithinnovations.com ML3NGPZG8PS3 116925606 88BH3 SBA SBC Identification Number: 001616419 Firm Certificate OFFEROR CERTIFIES THAT: 1.\nIt has no more than 500 employees, including the employees of its affiliates.\n2.\nNumber of employees including all affiliates (average for preceding 12 months) 3.\nThe business concern meets the ownership and control requirements set forth in 13 C.F.R.\nSection YES 35 YES 121.702.\n4.\nVerify that your firm has registered in the SBAS Company Registry at www.sbir.gov by providing the SBC_001616419 SBC Control ID# and uploading the registration confirmation PDF: Supporting Documentation:",
        "3": "\u2022 SBC_001616419 (3).pdf 5.\nIt has more than 50% owned by a single Venture Capital Owned Company (VCOC), hedge fund, or private equity firm 6.\nIt has more than 50% owned by multiple business concerns that are VOCs, hedge funds, or private NO NO equity firms?\n7.\nThe birth certificates, naturalization papers, or passports show that any individuals it relies upon to YES meet the eligibility requirements are U.S.\ncitizens or permanent resident aliens in the United States.\n8.\nIs 50% or more of your firm owned or managed by a corporate entity?\n9.\nIs your firm affiliated as set forth in 13 CFR Section 121.103?\n10.\nIt has met the performance benchmarks as listed by the SBA on their website as eligible to participate 11.\nFirms PI, CO, or owner, a faculty member or student of an institution of higher education NO NO YES NO 12.\nThe offeror qualifies as a: [ ] Socially and economically disadvantaged SBC [ ] Women-owned SBC [ ] HUBZone-owned SBC [X] Veteran-owned SBC [X] Service Disabled Veteran-owned SBC [ ] None Listed 13.\nRace of the offeror: [ ] American Indian or Alaska Native [ ] Native Hawaiian or Other Pacific Islander [ ] Asian [X] White [ ] Black or African American [ ] Do not wish to Provide 14.\nEthnicity of the offeror: NON- HISPANIC 15.\nIt is a corporation that has some unpaid Federal tax liability that has been assessed, for which all FALSE judicial and administrative remedies have not been exhausted or have not lapsed, and that is not being paid in a timely manner pursuant to an agreement with the authority responsible for collecting the tax liability: 16.\nFirm been convicted of a fraud-related crime involving SBIR and/or STTR funds or found civilly liable NO for a fraud-related violation involving federal funds: 17.\nFirms Principal Investigator (PI) or Corporate Official (CO), or owner been convicted of a fraud-related NO crime involving SBIR and/or STTR funds or found civilly liable for a fraud-related violation involving federal funds: Signature: Printed Name Signature Title Business Name Date",
        "4": "Kristopher Pruitt Kristopher Pruit CEO Cenith Innovations, LLC 06/19/2020 t Audit Information Summary: Has your Firm ever had a DCAA review?NO VOL I - Proposal Summary Summary: Proposed Base Duration (in months): 6 Technical Abstract: Department of Defense and Intelligence Community analysts and operators providing situational awareness, building patterns of life, performing threat detection, or conducting targeting operations have seen an overwhelming increase in data volume, velocity, and variety for decades.\nThese analysts and operators face numerous priorities, including more complex and time- sensitive questions from commanders and decision-makers.\nLimited by time and technical tools to perform advanced data science on incoming data, they often must leave behind tranches of valuable unanalyzed data and delay updates to intelligence databases such as knowledge graphs.\nKnowledge graphs are powerful tools for understanding the world and supporting the types of analysis mentioned above, because they offer a structured, highly interconnected way of organizing and representing knowledge.\nThe knowledge graphs' capability to model complex relationships between entities allows them to aid analysts and other users in discovering insights and asking questions that other data structures often do not provide or allow.\nKnowledge graphs are the basis for modern internet searches and make Large Language Models and tools like ChatGPT more accurate and reliable.\nIn a world with ever-increasing volume, velocity, and variety of data, knowledge graphs are pivotal in bringing the DoD and IC technology to a level where users can ask their intelligence systems the same questions they ask Google and ChatGPT in their everyday lives.\nA major part of delivering this capability to the DoD and IC will be creating more efficient, transparent, and accurate methods to update knowledge graphs.\nCurrently, updating knowledge graphs and other intelligence databases often relies on time-consuming, heuristic-based, manual methods that can be arbitrary and oversimplified compared to reality.\nThis can lead to knowledge graphs becoming brittle, unreliable, and inaccurate.\nCenith Innovations proposes applying recent advances in Graph Neural Networks and novel attention mechanisms to build and test a more efficient, transparent, and accurate capability to make it easier for users to interpret, update, and organize knowledge graphs.\nThis capability will allow users or automated data feeds to make changes and additions to the graph and have those changes recommend additional updates that should be made to the knowledge graph.\nWe propose pursuing both a more",
        "5": "manual method by recommending changes to be verified by users, as well as a more automated and scalable method by building a transparent system to automatically update knowledge graph changes that users will trust.\nAnticipated Benefits/Potential Commercial Applications of the Research or Development: By enhancing the scalability and accuracy of dynamic knowledge graphs, analysts can focus more on deriving insights rather than manual data management.\nWe will test and prove the feasibility of using Graph Neural Networks, specifically Graph Attention Networks, and a novel attention mechanism we identify as an Update Impact Prediction Network to make updating the DOD and IC\u2019s dynamic knowledge graphs more scalable, accurate, adaptable, and easier.\nWe will focus on ways to massively decrease the burden on users to upkeep knowledge graphs, as well as promote a transparent approach that helps build trust with users in an automated update system.\nAttention: Disclaimer: For any purpose other than to evaluate the proposal, this data except proposal cover sheets shall not be disclosed outside the Government and shall not be duplicated, used or disclosed in whole or in part, provided that if a contract is awarded to this proposer as a result of or in connection with the submission of this data, the Government shall have the right to duplicate, use or disclose the data to the extent provided in the funding agreement.\nThis restriction does not limit the Government's right to use information contained in the data if it is obtained from another source without restriction.\nThis restriction does not apply to routine handling of proposals for administrative purposes by Government support contractors.\nThe data subject to this restriction is contained on the pages of the proposal listed on the line below.\nAddition: Enter the page numbers separated by a space of the pages in the proposal that are considered proprietary: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 List a maximum of 8 Key Words or phrases, separated by commas, that describe the Project: Knowledge Graph, AI/ML, GNNs, Update Impact Prediction Network, data management, knowledge management, GANs, LLM Summary: VOL I - Proposal Certification 1.\nAt a minimum, two thirds of the work in Phase I will be carried out by your small business as defined by 13 C.F.R YES Section 701-705.\nThe numbers for this certification are derived from the budget template.\nTo update these numbers, review and revise your budget data.\nIf the minimum percentage of work numbers are not met, then a letter of explanation or written approval from the funding officer is required.\nPlease note that some components will not accept any deviation from the Percentage of Work (POW) minimum",
        "6": "requirements.\nPlease check your component instructions regarding the POW requirements.\nFirm POW Subcontractor POW 100% 0% 2.\nIs primary employment of the principal investigator with your firm as defined by 13 C.F.R Section 701-705?\nYES 3.\nDuring the performance of the contract, the research/research and development will be performed in the YES United States.\n4.\nDuring the performance of the contract, the research/research and development will be performed at the YES offerors facilities by the offerors employees except as otherwise indicated in the technical proposal.\n5.\nDo you plan to use Federal facilities, laboratories, or equipment?\n6.\nThe offeror understands and shall comply with export control regulations.\n7.\nThere will be ITAR/EAR data in this work and/or deliverables.\nNO YES YES 8.\nHas a proposal for essentially equivalent work been submitted to other US government agencies or DoD NO components?\n9.\nHas a contract been awarded for any of the proposals listed above?\n10.\nFirm will notify the Federal agency immediately if all or a portion of the work authorized and funded under this proposal is subsequently funded by another Federal agency.\nNO YES 11.\nAre you submitting assertions in accordance with DFARS 252.227-7017 Identification and assertions use, NO release, or disclosure restriction?\n12.\nAre you proposing research that utilizes human/animal subjects or a recombinant DNA as described in DoDI NO 3216.01, 32 C.F.R.\nSection 219, and National Institutes of Health Guidelines for Research Involving Recombinant DNA of the solicitation: 13.\nIn accordance with Federal Acquisition Regulation 4.2105, at the time of proposal submission, the required YES certification template, \"Contractor Certification Regarding Provision of Prohibited Video Surveillance and Telecommunications Services and Equipment\" will be completed, signed by an authorized company official, and included in Volume V: Supporting Documents of this proposal.\nNOTE: Failure to complete and submit the required certifications as a part of the proposal submission process may be cause for rejection of the proposal submission without evaluation.\n14.\nAre teaming partners or subcontractors proposed?\nNO 15.\nAre you proposing to use foreign nationals as defined in 22 CFR 120.16 for work under the proposed effort?\nNO 16.\nWhat percentage of the principal investigators total time will be on the project?\n17.\nIs the principal investigator socially/economically disadvantaged?\n51% NO 18.\nDoes your firm allow for the release of its contact information to Economic Development Organizations?\nYES VOL I - Contact Information Principal Investigator Name: Mr.\nBryan O'Rourke",
        "7": "Phone: (661) 312-3063 Email: bryan@cenithinnovations.com Address: 61142 Ridge Falls Place, Bend, OR 97702 - Corporate Official Name: Kristopher Pruitt Phone: (916) 707-3178 Email: kris@cenithinnovations.com Address: 1861 9th Avenue, Sacramento, CA 95818 - 4111 Authorized Contract Negotiator Name: Dane Kaiser Phone: (207) 441-5569 Email: dane@cenithinnovations.com Address: 1861 9th Avenue, Sacramento, CA 95818 - 4111 Form Generated on 11/06/2024 11:30:26 AM",
        "8": "Cenith Innovations, LLC: Topic Number: AF244-0001, Proposal Number: F244-0001-0094 Faster, Easier, and More Accurate Automated Updating of Dynamic Knowledge Graphs for Intelligence and Operations Using Graph Attention Networks and Update Impact Prediction Networks Volume 2: Technical Volume Graph Attention Networks and Novel Attention Mechanisms for Interpreting, Updating, and Organizing Knowledge Graphs Department of Defense (DoD) and Intelligence Community (IC) analysts and operators providing situational awareness, building patterns of life, performing threat detection, or conducting targeting operations have seen an overwhelming increase in data volume, velocity, and variety for decades.\nThese analysts and operators face numerous priorities, including more complex and time-sensitive questions from commanders and decision-makers.\nLimited by time and technical tools to perform advanced data science on incoming data, they often must leave behind tranches of valuable unanalyzed data and delay updates to intelligence databases, including knowledge graphs.\nKnowledge graphs are powerful tools for understanding the world and supporting the types of analysis mentioned above because they offer a structured, highly interconnected way of organizing and representing knowledge.1 2 The knowledge graph\u2019s capability to model complex relationships between entities allows them to aid analysts and other users in discovering insights and asking questions that other data structures often do not provide or allow.\nKnowledge graphs are the basis for modern internet searches and make Large Language Models and tools like ChatGPT more accurate and reliable.\nIn a world with ever-increasing volume, velocity, and variety of data, knowledge graphs are pivotal in bringing the DoD and IC technology to a level where users can ask their intelligence systems the same questions they ask Google and ChatGPT in their everyday lives.\nA major part of delivering this capability to the DoD and IC will be creating more efficient, transparent, and accurate methods to update knowledge graphs.\nCurrently, updating knowledge graphs and other intelligence databases often relies on time-consuming, heuristic-based, manual methods that can be arbitrary and oversimplified compared to reality.\nThis can lead to knowledge graphs becoming brittle, unreliable, and inaccurate.\nCenith Innovations proposes applying recent advances in Graph Neural Networks (GNNs) and novel attention mechanisms to build and test a more efficient, transparent, and accurate capability to make it easier for users to interpret, update, and organize knowledge graphs.\nThis capability will allow users or automated data feeds to make changes and additions to the graph and have those changes recommend additional updates that should be made to the knowledge graph.\nWe propose pursuing both a manual method that will recommend changes to be verified by users and a more automated and scalable method by building a transparent system that automatically updates knowledge graph changes that users will trust.\nDuring this Phase I effort, Cenith Innovations will test and prove the feasibility of using GNNs, specifically Graph Attention Networks (GATs), and a novel attention mechanism we identify as an \u201cUpdate Impact Prediction Network\u201d (UIPN) to make updating the DOD and IC\u2019s dynamic knowledge 1 Ji, Pan, Marttinen, Yu; \u201cA Survey on Knowledge Graphs: Representation, Acquisition and Applications\u201d, IEEE Transactions on Neural Networks and Learning Systems, arxiv.org/abs/2002.00388, April 2021 2 Peng, Xia, Naseriparsa, Osborne, \u201cKnowledge Graphs: Opportunities and Challenges\u201d, arxiv.org/pdf/2303.13948, March 2023 This proposal includes data that shall not be disclosed outside the Government and shall not be duplicated, used, or disclosed-in whole or in part-for any purpose other than to evaluate this proposal.\nIf, however, a contract is awarded to this proposer as a result of-or in connection with-the submission of this data, the Government shall have the right to duplicate, use, or disclose the data to the extent provided in the resulting contract.\nThis restriction does not limit the Government's right to use information contained in this data if it is obtained from another source without restriction.\nThe data subject to this restriction are contained in pages 1-17.\n1",
        "9": "Cenith Innovations, LLC: Topic Number: AF244-0001, Proposal Number: F244-0001-0094 graphs more scalable, accurate, adaptable, and easier.\nDuring this effort, we will focus on ways to massively decrease the burden on users to upkeep knowledge graphs, as well as promote a transparent approach that helps build trust with users in an automated update system.\nFigure 1: A common knowledge graph relationship node structure shown on the left (a) followed by a potential example of the employment of GATs unlocking previously unconnected node structures.\nPhase I Technical Objectives Introduction to Proposed Project: Our proposed research and testing explores the feasibility of applying GATs with UIPNs, our novel attention mechanism,3 to automate and increase the accuracy of updating and analyzing knowledge graph data to include flagging important updates for users to verify for approval.\nDelivering this capability will allow users to focus more on interpreting insights instead of manually managing data.\nAdditionally, since users may receive intelligence on numerous entities from numerous sources, \u201cupdating the graph\u201d should not be limited to only entities already represented in the graph, so we have included work to use GATs and UIPNs to efficiently, intuitively, and accurately add, remove, and update nodes and edges from external, non-graph data sources.\nOur proposed technical approach using GATs and UIPNs will make updating and managing dynamic knowledge graphs more scalable, accurate, adaptable, and easier.\nOur approach is differentiated from other approaches that only use Graph Convolutional Networks (GCNs) or GATs by themselves because of the addition of our UIPN, and the result will be: \u25cf Scalable: Enables the benefits of GATs to efficiently handle large-scale knowledge graphs by limiting updates to affected nodes.4 However, our proposed addition of the UIPN will enable higher-quality updating across a larger neighborhood of nodes compared to GATs or other types of GNNs alone.\n\u25cf Accurate: Reality doesn\u2019t follow the heuristics leveraged by GATs alone to determine which knowledge graph elements should be updated (i.e., neighborhood size).\nOur UIPN is trained 3 Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, Polosukhin; \u201cAttention is All You Need\u201d, 31st Conference on Neural Information Processing Systems, arxiv.org/pdf/1706.03762, June 2017 4 Velickovic, Cucurull, Casanova, Romero, Lio, Bengio; \u201cGraph Attention Networks\u201d, Published as a conference paper at International Conference on Learning Representations (ICLR) 2018, arxiv.org/pdf/1710.10903; April 2018 Use or disclosure of data contained on this page is subject to the restriction on the first page of this volume.\n2",
        "10": "Cenith Innovations, LLC: Topic Number: AF244-0001, Proposal Number: F244-0001-0094 specifically to offer more accurate predictions about which graph elements should be updated and, therefore, improves the accuracy of automatically updated nodes and edges.\nThis applies especially to long sequences of interconnected nodes across knowledge graphs.\n\u25cf Adaptable: The GAT and UIPN learn and adapt to new patterns of dependencies as the underlying data evolves, keeping automated updates scalable and accurate, as described above.\n\u25cf Easier and Faster: By simultaneously pursuing a manual verification of recommended changes and also building a capability to automatically make updates that will be more scalable in the future, our capability will greatly minimize the need for manual interventions and corrections.\nFurthermore, this research seeks to lay the groundwork for advanced analysis capabilities facilitated by GATs, such as pattern recognition and anomaly detection, which can help users uncover hidden connections and generate actionable intelligence, ultimately improving decision-making processes.\nIntroduction to Knowledge Graphs and GNNs: Knowledge graphs are a data structure that represents information in a graph format, with real-world entities depicted as nodes and their relationships as edges.\nThis structure allows for capturing complex interconnections between data points, which makes it easier to understand and analyze relationships within a given domain.\nKnowledge graphs can integrate diverse data sources, infer new knowledge, and provide a contextual understanding of information.5 These uses are particularly valuable in applications like search engines, recommendation systems, and intelligence analysis.\nGNNs are a class of neural networks designed to perform inference on data represented as graphs.\nUnlike traditional neural networks that operate on fixed-size input (like images or sequences), GNNs can handle the irregular structure of graphs, making them ideal for modeling relational data where entities (nodes) and their relationships (edges) are of primary interest.6 Graph Attention Networks are a type of GNN, but the defining characteristic of a GAT is its use of an attention mechanism to assign different weights to different neighboring nodes.\nThis allows the GAT to focus more on the most relevant nodes in the graph for each node's representation and makes GATs particularly effective for tasks where not all neighboring nodes contribute equally to a node's feature.7 Project Key Objectives: To prove the capability to intuitively and efficiently support users\u2019 interaction with and updating of knowledge graphs, our research will test and measure the feasibility of the following six objectives: 1.\nResearch and test methods to convert non-graph, tabular data into graph topology suitable for GATs, allowing the construction of nodes, edges, and embeddings that integrate seamlessly with existing graph structures and ontologies.\n2.\nEmploy GATs and our novel UIPNs to determine related updates across the graph when making changes, ensuring consistency and coherence.\nEnable capabilities for users to verify recommended changes and to allow automated updates where appropriate.\n5 Chaudhri, Chittar, Chenesereth; \u201cAn Introduction to Knowledge Graphs\u201d, ai.stanford.edu/blog/introduction-to-knowledge-graphs/, May 2021 6 Sanchez-Lengeling, Reif, Pearce, Wiltschko, \u201cA Gentle Introduction to Graph Neural Networks\u201d, distill.pub/2021/gnn-intro/, September 2021 7 Sanchez-Lengeling, Reif, Pearce, Wiltschko, \u201cA Gentle Introduction to Graph Neural Networks\u201d, distill.pub/2021/gnn-intro/, September 2021 Use or disclosure of data contained on this page is subject to the restriction on the first page of this volume.\n3",
        "11": "Cenith Innovations, LLC: Topic Number: AF244-0001, Proposal Number: F244-0001-0094 3.\nIdentify methods and best practices to ensure consistency during the GAT\u2019s initial training and through user-provided feedback in operations.\nInclude engagement with users to build best practices.\n4.\nUse GATs and UIPNs to intelligently filter, batch, and prioritize human reviews of nodes and edges that were automatically updated by GATs and UIPNs.\nInclude engagement with users to identify best practices.\n5.\nProvide metrics at different levels of the graph (entire graph, subsets of a graph, embeddings across multiple nodes and edges, specific nodes and edges) to keep users aware of when and how the knowledge graph is changing over time based on automatic and manual updates.\nInclude engagement with users to identify best practices.\n6.\nRecord snapshots of the GATs and UIPNs over time for use in subsequent graph analytics or other analytics.\nWe will use three data sets to test the feasibility of our approaches.\n\u25cf The Panama Papers graph database created by the International Consortium of Investigative Journalists captures a tangled web of offshore accounts and is aligned with defense and intelligence use cases.\n\u25cf The Armed Conflict Locator Events Database (ACLED) includes a graph of all battles, protests, and violent events in conflicts across the globe, including the identification of actors, and is aligned with defense and intelligence use cases.\n\u25cf Open Graph Benchmark\u2019s ogbl-collab is an undirected graph representing a subset of the collaboration network between research paper authors indexed by MAG.\nEach node within the graph represents an author, and edges indicate the collaboration between authors.\nThis dataset is commonly used to measure the performance of GNNs in the scientific community.\nAdditionally, we will use neo4j as our knowledge graph engine because of its integration with a well-known Cypher query language, large user community, and ability to transfer neo4j graph formats to other graph engine formats if necessary or desired.\nObjective #1: Research and test methods to convert non-graph, tabular data into graph topology suitable for GATs, allowing the construction of nodes, edges, and embeddings that integrate seamlessly with existing graph structures and ontologies.\nIntelligence analysts and other knowledge graph users rely on multiple data sources in varied formats to improve their analyses.\nThis includes data from sources external to the graph that may be delivered in tabular, relational, or textual formats and that may be incorporated manually or through pre-built data pipelines.\nUsers need help efficiently and accurately integrating these external data sources efficiently and effectively into their knowledge graphs and analyses.\nWe will achieve this objective by focusing first on tabular data.\nTextual data is another data type to focus on in future efforts.\nThe first step for tabular data will be to preprocess the data into nodes and edges.\nWe will treat each row as a potential node.\nThen, a GAT will use each row\u2019s attributes, including spatial or other attribute data, such as a vehicle type, a person\u2019s name, or a military force name, to create an edge between a record in the tabular data and a node in the knowledge graph.\nFor example, if a row recording a T-80 tank shares the same \u201cUnit Name\u201d attribute value with a node in the knowledge graph describing an Armored Tank Battalion, then the GAT will create a new \u201cT-80 tank\u201d node in the knowledge graph from the tabular data and create an edge between it and the Armored Tank Battalion.\nUse or disclosure of data contained on this page is subject to the restriction on the first page of this volume.\n4",
        "12": "Cenith Innovations, LLC: Topic Number: AF244-0001, Proposal Number: F244-0001-0094 Figure 2: A notional example showing the translation of individual nodes from a knowledge graph to nodes within the GAT.\nWe will use GATs to improve the accuracy and scalability of the required entity matching, relationship definition, edge creation, and feature engineering steps that need to occur for tabular data8 9 10.\n\u25cf GATs will assist in automating entity matching through learned similarity measures, which will make matching more scalable and accurate than traditional methods of similarity analysis, such as string matching.\n\u25cf GATs will assist with relationship definition by identifying patterns in the graph\u2019s structure and learned embeddings.\nThis will add new nodes that are more consistent and rich for the user\u2019s context.\n\u25cf GATs will suggest edge attributes for edge creation by analyzing existing nodes and their relationships.\nThey will use attributes from nodes and tabular data to ensure the correct relationship is defined.\nThis will often include spatial and other data contexts.\n\u25cf GATs will assist in identifying the relevant features to extract from the tabular data and convert them into the graph for feature engineering.\nAdditionally, they may convert attributes into the appropriate ingestible representations for the graph.\nWe expect these steps to deliver value because they will consider local and global knowledge graph contexts.\nThis method will help determine where newly added nodes and edges best fit in the existing topology to keep the graph accurate and relevant.\nObjective #2: Employ GATs and our novel UIPNs to determine related updates across the graph when making changes, ensuring consistency and coherence.\nEnable capabilities for users to verify recommended changes and to allow automated updates where appropriate.\nDynamic knowledge graphs allow users to externalize their knowledge in a digital format that can capture the complex, non-linear dependencies that traditional data structures and rule-based systems do not 8 Zhu, Ma, Wang; \u201cRAGA: Relation-aware Graph Attention Networks for Global Entity Alignment\u201d, arxiv.org/abs/2103.00791, March 2021 9 Ji, Hui, Luo; \u201cGraph Attention Networks With Local Structure Awareness for Knowledge Graph Completion\u201d, Institute of Electrical and Electronics Engineers, ieeexplore.ieee.org/document/9292922, December 2020 10 Han, Liu, Zhang, Li; \u201cHierarchical Perceptual Graph Attention Network for Knowledge Graph Completion\u201d, Use or disclosure of data contained on this page is subject to the restriction on the first page of this volume.\n5",
        "13": "Cenith Innovations, LLC: Topic Number: AF244-0001, Proposal Number: F244-0001-0094 capture.\nEffective knowledge graphs must also be updated efficiently and accurately so that users don\u2019t spend all their time managing their knowledge but instead apply and deliver it to warfighters.\nOur proposed approach is designed to improve performance and deliver better technical and mission results.\nBy offering efficient update propagation that avoids unnecessary computations, our method is scalable for the very large, dynamic graphs that the DoD and IC use for intelligence analysis and knowledge management.\nIncorporating the UIPN further boosts our efficiency and enables us to focus on the most impacted nodes, thereby improving prediction accuracy.\nThe joint operation of GAT and UIPN, adjusting thresholds for node updates based on learned patterns, ensures flexibility in different contexts, further enhancing our efficiency.\nWe will accomplish this objective by testing the application of six steps to recommend nodes be updated and then verified by users, as well as establish the capability to automatically update (when appropriate) nodes, edges, and their attributes and embeddings across the graph.\nOur model training approach, outlined in Objective #3, is intertwined throughout these six steps, which are listed below in this objective.\nEnabling users to verify automatically recommended updates to the knowledge graph will aid in our model training process and help build a repeatable process that will enable users to understand how a knowledge graph can be automatically updated in the future.\nWe will also add the UIPN element to the architecture.\nThe UIPN is a neural network built upon the GAT.\nIt is trained on the connections between nodes and enhanced with additional attention mechanisms.\nThe UIPN\u2019s input will be any updated node or edge embedding or contextual information from neighboring nodes; its output will be a probability distribution over other nodes that indicates the likelihood that each node will require an update.\nFigure 3: A notional example of the node structure affected by modified weights used by the described UIPN.\nThe additional attention mechanisms will focus the model\u2019s capacity on the most relevant parts of the knowledge graph by assigning attention weights to nodes based on their relevance to the updated node.\nThis allows the UIPN to prioritize nodes that are more likely to be affected and to recognize nodes that are connected along long chains of connections.\nThe six steps we will test are: 1.\nInitial Embedding Computation: Compute embeddings for all nodes and edges in the knowledge graph using their attributes and initial states.\n2.\nDependency Modeling with GAT: The GAT will process the graph to learn the dependencies between nodes.\nThe node embeddings are updated by aggregating information from neighboring nodes through message passing.\nUse or disclosure of data contained on this page is subject to the restriction on the first page of this volume.\n6",
        "14": "Cenith Innovations, LLC: Topic Number: AF244-0001, Proposal Number: F244-0001-0094 3.\nNode Update Event: After a node or edge is updated, automatically or manually, its embedding is recalculated to reflect the new state.\nThis updated embedding captures the change in the node\u2019s attributes and connections.\n4.\nUpdate Impact Prediction: The updated node\u2019s embedding is fed into the UIPN, which uses the GAT\u2019s learned dependencies and attention mechanisms to assess the update\u2019s impact on other nodes.\nThe UIPN outputs a probability score for each node that indicates the need for an update.\n5.\nPropagation of Updates: Nodes with probability scores above a certain threshold determined by the GAT are selected for updating.\nThese recommended updates can either be verified as correct or incorrect by a user or automatically propagated through portions of a knowledge graph or the entire knowledge graph.\nAfter updating, the nodes\u2019 and edges\u2019 embeddings are recalculated, and the process is iterated to capture multi-hop dependencies across multiple nodes.\n6.\nDynamic Adjustment: The UIPN and GAT integrated system continuously learns and adjusts the thresholds and attention weights based on user feedback, improving over time.\nObjective #3: Identify methods and best practices to ensure consistency during the GAT\u2019s initial training and through user-provided feedback in operations.\nInclude engagement with users to build best practices.\nThe GAT\u2019s initial training must be consistent with how ongoing training will occur in operations, so it is vital to judge tested approaches based on both model performance and the feasibility of ongoing model training via collecting user feedback when in operations.\nOur approach for training GATs and UIPNs includes three main steps: data collection, design of a loss function, and optimization.\nWe will collect data by simulating user-created, manual node and edge updates, additions, and removals, as well as creating new nodes and edges based on data meant to represent external, tabular data that a user would want to add to the graph.\nWe will create this simulated data in an inductive environment to add new nodes or edges to a graph and in a transductive environment to update existing nodes or edges.\nSimulated data for existing node and edge updates will include randomized node and edge updates, removals, additions, and human, expert-directed updates.\nSimulated data for new node and edge additions will involve the removal of select nodes and edges in the knowledge graph and then re-adding them as training data points.\nDuring model operations, we will collect data on node and edge updates and the subsequent impact on other nodes and edges in the knowledge graph.\nThis historical update data will be filtered, prioritized, and presented to users to identify as good or bad updates to neighboring nodes or edges.\nWe will design a loss function that penalizes incorrect predictions of node updates and balances precision and recall.\nIncorrect predictions will be identified by humans during our sampled, prioritized human assessment of automated changes, as described in Research Objective #4.\nLastly, for optimization, we will test using backpropagation to train the GATs and UIPNs jointly, which will ensure the model learns both the structural dependencies and dynamic propagation patterns.\nWe will conduct user-engagement sessions virtually or in person to verify assumptions and record best practices.\nObjective #4: Use GATs and UIPNs to intelligently filter, batch, and prioritize human reviews of nodes and edges that have been automatically updated by GATs and UIPNs.\nInclude engagement with users to identify best practices.\nGATs are trained on a specific knowledge graph, so it will be necessary to leverage users\u2019 expertise to provide feedback to the model to improve its training and performance.\nRequiring users to provide training input to models in the middle of their analytic workflow can be annoying and disruptive because Use or disclosure of data contained on this page is subject to the restriction on the first page of this volume.\n7",
        "15": "Cenith Innovations, LLC: Topic Number: AF244-0001, Proposal Number: F244-0001-0094 it can distract them from priorities, so we will identify ways to improve how users provide feedback to recommended knowledge graph updates that are identified below.\nWhile the DoD has collected much information on the effectiveness of labeling data for Computer Vision use cases, the same level of lessons learned and information does not exist regarding labeled data for DoD knowledge graphs.\nWe will seek to leverage best practices from Computer Vision labeling efforts and leverage our connections and experience in the DoD Computer Vision community so we can apply their expertise to GATs.\nWe will test the feasibility of effectively batching and prioritizing records for feedback and offer Active Learning options using the attention mechanisms and outputs of the UIPN to intuitively and easily collect feedback from users as they interact with the graph.\nFor example, based on performance and user feedback, we can implement a strategy to batch updates of different categories or groups of nodes and cue users to complete these regularly.\nWe can simultaneously provide Active Learning options for nodes or edges that we identify as more critical to the knowledge graph based on graph metrics.\nWe will ask users whether the GATs\u2019 and UIPNs\u2019 updates to a node or edge were good or bad, then use that feedback to continuously compute the graph embeddings and improve the UIPN and GAT through backpropagation as described in Objective #3.\nMuch of the work in this objective will jointly accomplish training the model while also providing users the ability to verify recommended updates to the knowledge graph before propagating changes throughout it.\nThe users\u2019 collected feedback on adding new nodes or edges will match the inductive environment of the initial training for new nodes and edges, and feedback collected on the updating of existing nodes or edges will match the transductive environment of the initial training for existing nodes and edges.\nWe will conduct user-engagement sessions virtually or in person to verify assumptions and record best practices.\nObjective #5: Provide metrics at different levels of the graph (entire graph, subsets of a graph, embeddings across multiple nodes and edges, specific nodes and edges) to keep users aware of when and how the knowledge graph is changing over time based on automatic and manual updates.\nInclude engagement with users to identify best practices.\nAutomated methods for knowledge management and updating knowledge graphs in intelligence analysis must be measured objectively over time to build trust and rapport with analysts and other users.\nUsers will quickly lose any time savings if they feel they must investigate the provenance of an automated update to a knowledge graph or if they can\u2019t easily understand why and how it was made.\nThis is why, as part of our research and feasibility testing, we will research the effectiveness of various graph metrics at the node, subgraph, and graph level to allow users to understand how their knowledge graph is changing over the short and long term.\nWe will build graph metrics and survey users and other potential users to determine the most useful metrics for building trust and rapport with users.\nWe will engage with potential users, either virtually or in person, to review several families of graph metrics and determine the best options to pursue: \u25cf Graph Structure Metrics: Number of nodes and edges, degree distribution, connectivity metrics, graph components, clustering coefficient, graph centrality \u25cf Graph Content Metrics: Attribute completeness, attribute changes, node and edge types, label changes \u25cf Graph Quality Metrics: Consistency metrics, redundancy metrics, data completeness, accuracy metrics \u25cf Dynamics Metrics: Change frequency, volatility metrics, temporal patterns \u25cf Usage Metrics: Query volume and coverage, feedback and corrections, human review metrics Use or disclosure of data contained on this page is subject to the restriction on the first page of this volume.\n8",
        "16": "Cenith Innovations, LLC: Topic Number: AF244-0001, Proposal Number: F244-0001-0094 Cenith Innovations has extensive experience conducting user feedback sessions with analysts and operators.\nWe will leverage our Design Thinking-based workshops to run interactive surveys using digital tools like iPads and survey tools such as Mentimeter to facilitate user sessions and record feedback in quantitative data that can be used in this Phase I project and beyond.\nCcnith Innovations proposes emphasizing this as part of a Phase I effort because even if a system is built that allows for faster, more automated updating of knowledge graphs, we will not achieve user adoption without a mechanism to explain the updates and characterize how they\u2019re affecting the overall graph over time.\nWe will conduct user-engagement sessions, virtually or in person, to verify assumptions and record best practices.\nObjective #6: Record snapshots of the GATs and UIPNs over time for use in subsequent graph analytics or other analytics.\nAnalysts\u2019 and other users\u2019 knowledge is a living, breathing artifact because they must always adapt to new knowledge and circumstances.\nRepresentations of their knowledge in dynamic knowledge graphs should be just as responsive and adaptable.\nWe expect that users from an operational and technical perspective will be interested in answering questions about how to analyze past versions of the graph that may have had differing numbers of nodes, connections between nodes, and other changed aspects.\nFor example, when knowledge graphs are updated automatically, it will be necessary for users to quickly comprehend what has changed in their graph since they last looked at a particular section of the graph in a specific context.\nWe will research the application of Delta Graph Visualizations and Temporal Evolution Charts using graph snapshots to help users understand how and when their graphs and subsections are changing based on automated updates.\nThis will also include the identification of structural anomalies and outliers that could indicate data quality issues or the addition of important new information.\nSimilar to Objective #5, we will conduct engagement sessions with potential users, in person or virtually, to gather feedback on the best methods.\nWe will leverage our extensive experience and Design Thinking approach to run interactive surveys using digital tools like iPads and survey tools such as Mentimeter to facilitate sessions with users and record feedback in quantitative data that can be used in this Phase I project and beyond.\nPlan to Accomplish Research Objectives: Objective #1: Research and test methods to convert non-graph, tabular data into graph topology suitable for GATs, allowing the construction of nodes, edges, and embeddings that integrate seamlessly with existing graph structures and ontologies.\nDays 0-30: Initial design and testing by ingesting non-graph data into a dynamic knowledge graph Days 30-60: Conduct user engagement to collect feedback on initial approaches Days 60-90: Iterate on the design and methods based on user feedback Days 90-120: Finalize design and methods in preparation for final testing Days 120-150: Conduct final testing and record results of methods for inclusion in the final report Days 150-180: Incorporate research objective findings into the final report and prototype design Use or disclosure of data contained on this page is subject to the restriction on the first page of this volume.\n9",
        "17": "Cenith Innovations, LLC: Topic Number: AF244-0001, Proposal Number: F244-0001-0094 Objectives #2 & 3: Employ GATs and our novel UIPNs to determine related updates across the graph when making changes, ensuring consistency and coherence.\nEnable capabilities for users to verify recommended changes and to allow automated updates where appropriate.\nIdentify methods and best practices to ensure consistency during the GAT\u2019s initial training and through analyst-provided feedback in operations.\nInclude engagement with users to build best practices.\nDays 0-30: Initial setup of dynamic knowledge graphs, GATs, and UIPNs Days 30-60: Initial training of GATs and UIPNs Days 60-90: Initial testing of updating knowledge graph elements on the fly and using GATs and UIPNs to update appropriate nodes and edges Days 90-120: Based on initial testing, iterate on overall GAT and UIPN training design and methods and implement changes in preparation for final testing Days 120-150: Conduct final testing and record results of methods for inclusion in the final report Days 150-180: Incorporate research objective findings into the final report and prototype design Objectives #3 & 4: Identify methods and best practices to ensure consistency during the GAT\u2019s initial training and through user-provided feedback in operations.\nInclude engagement with users to build best practices.\nUse GATs and UIPNs to intelligently filter, batch, and prioritize human reviews of nodes and edges that have been automatically updated by GATs and UIPNs.\nInclude engagement with users to identify best practices.\nDays 0-30: User engagement and initial designs related to updating a dynamic knowledge graph and recording feedback for continued GAT and UIPN training Days 30-60: Iterate and design an initial testable implementation of capability for users to update graphs; the graphs will be automatically updated by the GAT and UIPN, which will be trained based on user feedback Days 60-90: Initial testing of updating knowledge graph elements automatically, using GATs and UIPNs to update appropriate nodes, and collecting user feedback and training data to improve GATs and UIPN performance Days 90-120: Based on initial testing, iterate on the design and methods for collecting user feedback and training data.\nImplement changes in preparation for final testing.\nDays 120-150: Conduct final testing and record results of methods for inclusion in the final report Days 150-180: Incorporate research objective findings into the final report and prototype design Objective #5: Provide metrics at different levels of the graph (entire graph, subsets of a graph, embeddings across multiple nodes and edges, specific nodes and edges) to keep users aware of when and how the knowledge graph is changing over time based on automatic and manual updates.\nInclude engagement with users to identify best practices.\nDays 0-30: Set up initial metrics alongside dynamic knowledge graphs, GATs, and UIPNs Use or disclosure of data contained on this page is subject to the restriction on the first page of this volume.\n10",
        "18": "Cenith Innovations, LLC: Topic Number: AF244-0001, Proposal Number: F244-0001-0094 Days 30-60: Conduct engagement with end users to collect feedback on initial purposes and approaches to provide users with metrics.\nSeparately, record metrics during the initial training of GATs and UIPNs.\nImplement any required changes to metrics.\nDays 60-90: Record metrics during initial testing of automated updating knowledge graph elements using GATs and UIPNs Days 90-120: Improve or change metrics based on initial testing to support final testing Days 120-150: Conduct final testing, use developed metrics to measure performance, and include metrics in the final report Days 150-180: Incorporate research objective findings into the final report and prototype design Objective #6: Record snapshots of the GATs and UIPNs over time for use in subsequent graph analytics or other analytics.\nDays 0-30: Setup ability to take snapshots of knowledge graphs, GATs, and UIPNs Days 30-60: Record snapshots of knowledge graphs, GATs, and UIPNs Days 60-90: Record snapshots of knowledge graphs, GATs, and UIPNs Days 90-120: Build a plan for the best way to record snapshots during final testing Days 120-150: Conduct final testing and record snapshots of knowledge graphs, GATs, and UIPNs throughout testing.\nDays 150-180: Incorporate research objective findings into the final report and prototype design Phase I Statement of Work This Statement of Work outlines the major tasks and deliverables for experimenting and testing the feasibility of GATs and UIPNs to allow for user modifications to a dynamic knowledge graph and predict additional necessary changes to the graph, obtain baseline performance metrics such as but not limited to accuracy and graph completeness, initial prototype design completion, and documentation of all work completed, all of which will aid in selecting the most promising approach for further research and development.\nAdditionally, Cenith Innovations will work with the Government to identify appropriate end-users to engage with in interactive feedback sessions during the period of performance.\nScope: During the six-month period of performance, Cenith Innovations will incrementally develop and deliver tests and test results that will demonstrate GATs\u2019 and UIPNs\u2019 performance in allowing user modifications to dynamic knowledge graphs and predicting additional changes, culminating in an initial prototype design and a final feasibility report by the end of the period of performance.\nUse or disclosure of data contained on this page is subject to the restriction on the first page of this volume.\n11",
        "19": "Cenith Innovations, LLC: Topic Number: AF244-0001, Proposal Number: F244-0001-0094 Task Task Name Duration Expected Milestone Performer(s) Initial knowledge graph, GAT, UIPN setup Initial training of GAT and UIPN Initial testing and testing results Continued iterative development on overall GAT and UIPN training and data ingest Initial Prototype Design Final Testing 01 02 03 04 05 06 07 Days 0-30 Deliverables: Status report, virtual or in-person demo Bryan O\u2019Rourke Days 30-60 Days 60-90 Deliverables: Status report, virtual or in-person demo Colin Blackett Deliverables: Status Report, virtual or in-person demo Colin Blackett Days 90-120 Deliverables: Status Report, virtual or in-person demo Colin Blackett Days 120-180 Days 120-150 Deliverables: Prototype design document Ryan Tomlinson and Chris Lauber Deliverables: Status Report, virtual or in-person demo.\nDeliverables: Final Technical Report including test findings, baseline performance metrics, and documentation of work completed in this feasibility study, SF 298 Colin Blackett Bryan O\u2019Rourke Test Findings and Final Technical Report Days 150-180 Related Work Cenith Innovations simplifies warfighter and analyst workflows and improves analytic products and outcomes by applying novel AI solutions and engaging closely with users.\nWe exemplify this expertise across multiple projects, but most convincingly with PATH, an AI-driven product we developed for the US Army.\nPATH applies neural network-based Generative Adversarial Network (GAN) and Deep Reinforcement Learning (DRL) to aid soldiers in planning and navigating impossibly large combinatorial scenarios.\nOur work using these neural network-driven methods on PATH will directly benefit our proposed work when testing the feasibility of applying neural network-based GATs and UIPNs to provide automated, accurate updates to knowledge graphs.\nFor example, our DRL, GAN, and GAT work are all grounded in deep learning principles, including neural network architectures, backpropagation, and gradient descent algorithms, and all involve complex architectures to model agents and environments and handle high-dimensional and unstructured data.\nPATH\u2019s main customer is US Army SGM Corey Wilkens, corey.d.wilkens@army.mil, 417-650-1572.\nCenith Innovations\u2019 work on PATH is currently ongoing.\nPATH provides a robust human-in-the-loop Course of Action (COA) analysis powered by two primary AI capabilities that allow for human override and customization of the recommended outputs.\nThis analysis ensures users are not beholden to a predicted COA and can still use their intuitive knowledge of the battlespace to work in concert with the technology and make optimal decisions.\nThe first such AI capability uses a diffusion model, which is a type of generative AI model.\nOur diffusion model incorporates terrain features (e.g., surface, elevation, mobility factors, adversary locations, and doctrine) and creates a heatmap of undiscovered obstacles and threats.\nOur diffusion model uses a custom-built and trained Generative Adversarial Network (GAN) that learns how to \u201ccomplete the picture\u201d by filling Use or disclosure of data contained on this page is subject to the restriction on the first page of this volume.\n12",
        "20": "Cenith Innovations, LLC: Topic Number: AF244-0001, Proposal Number: F244-0001-0094 in the missing information on the map.\nGANs are trained by building images and judging how good a generated image is by comparing it to a set of coded discriminators.\nOur discriminators are essentially map inputs, such as map layers, manual annotations, or even enemy doctrine.\nOur diffusion model can look at an incomplete threat picture and incorporate all layers and inputs to produce a probabilistic map overlay of the missing threats, drastically improving the accuracy of the threat pictures.\nThe second AI capability Path uses for first-level terrain analysis is the ability to produce a detailed set of COAs.\nTo do this, we take the known key terrain features and fuse them with the probabilistic heat map from the diffusion model.\nThe combined data feeds into an RL algorithm, combined with a pathfinding algorithm (A*- pronounced \u201cA Stars\u201d) to produce an optimal set of possible COAs, balancing survivability with speed.\nWe built this model using a Markov Decision Process (MDP) that evaluates all possible next and future moves and actions while assigning a multivariate score and assessing the highest scoring potential.\nThese scores are determined using a reward function that incorporates the particular terrain, threats, location on the map, previous action, and resource availability.\nWe train the reward function and RL agent in simulated terrain environments called an RL gym.\nIn practice, there are too many possible combinations of moves and actions to practically compute the best path.\nThis is where A* comes into play.\nA* is an algorithm used by applications like Google Maps to quickly find the optimal path while following an impossibly large decision tree.11 We utilize A* to help the MDP explore the graph of possible moves and associated actions and to come up with a list of optimal COAs that maximize the reward function.\nThe end result is an output list of COAs, where each COA consists of attributes like an action to take at each step, the expected time to take that action and movement, and the expected danger or attrition rate for personnel and equipment along the way.\nRelationship with Future Research or Research and Development Anticipated Results of a Successful Phase I: Cenith Innovations records objective test results to inform and identify the most promising approach.\nWe anticipate that using GATs and UIPNs for knowledge graph updating will yield new, beneficial results to include more accurate neighborhood sizing for attention mechanisms, new findings regarding best training approaches for knowledge graphs related to DoD and IC use cases, how to efficiently and effectively retrieve GAT and UIPN training feedback from users, and improved methods for measuring how automated updates change the knowledge graph.\nPhase I Provides Foundation for a Phase II Research and Development Effort: With an objective foundation of test results and metrics from a successful Phase I, Cenith Innovations will build the momentum for delivering a functional prototype in a potential Phase II effort.\nBy successfully accomplishing the six identified research objectives, Cenith Innovations will have all the required technical architecture and proven methods and will have built an initial relationship with end users.\nObjective 1: Testing this capability requires us to build a basic prototype to identify and test how non-graph data can be ingested in the knowledge graph to update related nodes.\nThis basic prototype will be built in an extensible manner following Modular Open Source guidelines to facilitate continued development during a Phase II effort.\nObjectives 2 & 3: The required machine learning architecture and training environments to support a successful Phase II effort will be built during the Phase I effort.\nAdditionally, our testing results lead to an 11 Patel, Amit.\nIntroduction to A*, Amit Patel, 4 Nov.\n2023, theory.stanford.edu/~amitp/GameProgramming/.\nUse or disclosure of data contained on this page is subject to the restriction on the first page of this volume.\n13",
        "21": "Cenith Innovations, LLC: Topic Number: AF244-0001, Proposal Number: F244-0001-0094 improved GAT and UIPN training process, which will help more quickly and accurately ingest and train new customer data sources provided by the Air Force.\nObjective 4: Testing this capability will require a basic prototype for users to provide feedback on, which will be built in an extensible manner following Modular Open Source guidelines to facilitate continued development during a Phase II effort.\nObjective 5: Cenith Innovations is a data-driven organization.\nMetrics developed during Phase I will be continuously improved across Phase I and Phase II to objectively measure our capability\u2019s performance.\nObjective 6: We included this objective in our Phase I almost exclusively to be able to use this data during a potential Phase II effort.\nTime is a fundamental component of analysts\u2019 and operators\u2019 workflows; therefore, viewing and understanding how knowledge graphs change over time will be pivotal.\nWe will use snapshots generated in Phase I training to improve our Research and Development of temporal analysis of knowledge graphs in a potential Phase II effort.\nClearances and Approvals Required to Conduct Phase II Testing: Cenith Innovations includes several assumptions in its plan to support the Air Force\u2019s Phase II goal of demonstrating a full-scale prototype via on-site testing in the customer\u2019s environment.\nIf these assumptions are not correct, then additional conversations with the Government will need to be conducted before a Phase II proposal is submitted.\n1.\n\u201cFull-scale\u201d prototype means a prototype fully demonstrating the agreed-upon capability identified through a Phase II proposal, which will be based on Phase I results.\n2.\n\u201cOn-site testing in the customer\u2019s environment \u201d means testing on a network or system that does not require any cyber authorizations, such as an Authorization to Operate (ATO).\n3.\nThe Air Force will provide data in support of the Phase II demonstration, which may be classified.\nTo address assumption 1, Cenith Innovations will continuously communicate with the Air Force Technical Point of Contact (TPOC) throughout Phase I to ensure a common understanding of Phase II goals, which will be included in a Phase II proposal.\nTo address assumption 2, Cenith Innovations will architect our solution so that it can run locally on a server or computer that Cenith Innovations or the Air Force will provide.\nCenith Innovations will work with the Air Force to identify the exact technical details for the demonstration and include them in the Phase II proposal.\nTo address assumption 3, all Cenith Innovations team members for this project already maintain Secret-level clearances, with several team members maintaining TS clearance with access to SCI.\nAll Phase I work is unclassified and performed in our secure IL4 AWS GovCloud environment.\nCenith Innovations will engage the Air Force during the Phase I period of performance to understand the Air Force\u2019s goals and data classification requirements for the Phase II demonstration.\nBased on the Air Force\u2019s goals and requirements, Cenith will determine how development and demonstrations will occur at what classification levels to support a Phase II demonstration and overall meeting of Air Force goals.\nCommercialization Strategy Cenith Innovations is a profitable defense technology company with >$9M in annual revenue, specializing in rapidly building and deploying applied AI and advanced software at the speed and scale warfighters deserve.\nCenith was founded in 2019 by Kristopher Pruitt and Bryan O\u2019Rourke.\nKristopher was the U-2S Dragon Lady Functional Area Manager on the Headquarters Air Force Staff, working for the Deputy Chief of Staff for ISR and cyber effects operations.\nBryan was a Silicon Valley ML software engineer who began working with the DoD on Project Maven.\nTheir unique combination of operational Use or disclosure of data contained on this page is subject to the restriction on the first page of this volume.\n14",
        "22": "Cenith Innovations, LLC: Topic Number: AF244-0001, Proposal Number: F244-0001-0094 and technical expertise has led to significant growth of the company and the commercialization of multiple product offerings.\nCenith has supported several customers in the US Air Force, US Army, and the USSOCOM on efforts including Advanced Synthetic Aperture Radar System (ASARS) and Avionics Technology Refresh (ATR) for the U-2 Dragon Lady, Holistic Health and Fitness application development for the XVIII Airborne Corps, and LiDAR-generated Alternative Position and Navigation for the Family of Special Operations Vehicles.\nOur team includes PhD researchers, software and hardware engineers, remote sensing specialists, and geospatial analysts, each with decades of experience.\nSince our inception, we\u2019ve increased our revenue by an average of 164% year-over-year by applying our expertise, service, and products to meet DoD needs while providing exceptional quality.\nOur customers include One Nation Innovation, Leidos, General Dynamics Information Technology, Modern Technology Solutions Incorporated, Huntington Ingalls Industries, Draper Laboratories, Collins Aerospace, the United States Army, US Special Operations Command, and the USAF, among others.\nWe deliver bleeding-edge software development to those who need it the most.\nOur GAT and UIPN technology is highly dual-use.\nOur commercialization strategy effectively executes market entrance, adoption, and growth in both commercial and DoD markets.\nDue to the specificity of the topic, required technology, and our go-to-market capabilities, the Defense market is our first target.\nWe will align requirements, resources, contracting, and testing/validation to meet this goal.\nLOE 1: We will initially target existing DoD and IC programs that leverage knowledge graphs for intelligence analysis by focusing on business-to-business relationships with the Primes for these large enterprise contracts.\nThe particular contracts we\u2019re interested in include DIA\u2019s Machine-Assisted Analytic Rapid-Repository System (MARS), NGA\u2019s Cedalion capability, NGA\u2019s Structured Observation Management (SOM) program, and the Air Force Research Laboratory\u2019s Insight Integration program.\nFigure 4: Cenith Innovations Revenue Projections through 2029.\nLOE 2: We propose a pilot integration of third-party capabilities developed by small businesses, such as the ones developed through this SBIR, into the AFRL Insight Integration program.\nThis work may be conducted under a Cooperative Research and Development Agreement (CRADA) or in the form of a SBIR Phase III.\nDuring this LOE, we will work with GSA to stand up a SBIR Phase III indefinite delivery, indefinite quantity (IDIQ) contract with assistance from the SBIR Technical Point of Contact.\nIn addition to the GSA IDIQ we will maintain and mature our existing contract vehicles, which include multiple consortium OTAs (Consortium Management Group, Expeditionary Mission Consortium - Crane, and the Defense Industrial Base Consortium) along with large value and scope vehicles such as LOGIX (through FedSim), all of which can be leveraged by AFRL and other customers.\nUse or disclosure of data contained on this page is subject to the restriction on the first page of this volume.\n15",
        "23": "Cenith Innovations, LLC: Topic Number: AF244-0001, Proposal Number: F244-0001-0094 LOE 3: Cenith Innovations will take advantage of the large and growing markets that are already leveraging GNNs to automatically and accurately update enterprise dynamic knowledge graphs but may be limited by current implementations using Graph Convolutional Networks or GATs on their own.\nOur two target market segments are Knowledge Management & Customer Support and Real-time Fraud Detection in Financial Services.\nFor Knowledge Management & Customer Support, we will solve the pain points of constant update requirements that are costly and time-consuming.\nIn this segment, the GAT would infer the relevance of solutions, while the UIPN would predict the impact of the new support tickets or content updates on the existing knowledge graph.\nThe Total Addressable Market (TAM) for this market is approximately $500 billion, the Serviceable Available Market (SAM) is approximately $125 million, and the SOM is valued at around $6.25 billion with a SOM growth rate of approximately 18% annually, according to market research firm MarketsandMarkets.\nThe Financial Fraud Detection industry uses knowledge graphs to track relationships between users, accounts, transactions, and devices.\nKnowledge graphs must constantly be updated with every new transaction so they can be analyzed and used to detect potentially fraudulent activity.\nIn this example, the GAT would identify suspicious patterns based on existing relationships, while the UIPN would enable the network to adapt to new transactions.\nWith updates being provided faster and more accurately by the UIPN, the system can also flag potential fraud more quickly and accurately.\nThe TAM for Financial Fraud detection is approximately $40 billion, The Serviceable Available Market is approximately $24 billion, and the SOM for this market is valued at around $2.4 billion, according to MarketsandMarkets.\nProject Key Personnel Name and Title Employer Qualifications KEY PERSONNEL SUMMARY Bryan O'Rourke, Principal Investigator Cenith Innovations Bryan O\u2019Rourke has over a decade of experience as a software engineer and architect at industry-leading companies in Silicon Valley and Defense Technology.\nHis projects include several notable DoD-specific ML projects, such as Project Maven.\nBryan was the architect for Cenith Innovation\u2019s ML approach to build its successful PATH application for the US Army.\nHis overlap of experience with DoD platforms, software engineering leadership in Silicon Valley, and experience delivering projects in secure government environments make him an ideal Principal Investigator.\nBryan maintains a Secret security clearance.\n*Foreign National (Y/N) N Colin Blackett, Principal Engineer Cenith Innovations Colin Blackett has over 25 years of experience as a full-stack software engineer, software architect, and DevSecOps engineer in various roles across private technology companies and the DoD.\nHe\u2019s been an engineering team leader and software development manager and has broad expertise in producing rich and insightful AI/ML models and advanced mathematics.\nColin maintains a Secret security clearance.\nN Use or disclosure of data contained on this page is subject to the restriction on the first page of this volume.\n16",
        "24": "Cenith Innovations, LLC: Topic Number: AF244-0001, Proposal Number: F244-0001-0094 Ryan Tomlinson Director of Product Management Cenith Innovations Cenith Innovations Chris Lauber, Vice President of Defense and Intelligence Solutions Ryan Tomlinson has over 13 years of management experience with 8 years as a software engineer and 5 years as a product manager.\nRyan is a product leader who turns complex user requirements into successful and beautiful products.\nHe has extensive experience working with various tools to gain insight into user needs, workflows, and detailed technical integrations.\nRyan maintains a Secret security clearance.\nChris Lauber has over 18 years of experience as Senior Intelligence Analyst and Product Manager in the Intelligence Community and DoD.\nHe has extensive experience using Intelligence Community tools that leverage knowledge graphs, including leading the development of an analytic tool that extensively leveraged knowledge graphs while at the National Geospatial-Intelligence Agency.\nChris maintains a Top Secret security clearance and is eligible for TS//SCI access.\nN N Foreign Citizens Cenith Innovations is a domestically owned company.\nNo non-US citizens will participate in this effort.\nWe have no foreign ownership, control, or influence and maintain a TOP SECRET facility security clearance under CAGE 88BH3.\nCurrently, over 80% of our workforce has a SECRET clearance or above, and over 60% has a TOP SECRET, Sensitive Compartmented Information and/or Special Access Program clearance.\nSubcontractors/Consultants None.\nFacilities/Equipment All software development will be accomplished using Cenith Innovations\u2019 IL 4 AWS GovCloud environment.\nSoftware will be DFARS 252.204-7012, NIST 800-171, and NIST 800-53 compliant.\nAll data is encrypted in transit and at rest with AES256 keys.\nAll data in transit, including API calls, are encrypted with SSL/TLS1.2+.\nAuthentication uses OAuth 2 protocol and SSO.\nSecure 2 Factor Authentication can be enabled, including for mobile.\nAuthentication SIEM monitoring and alerting uses cutting-edge AWS GovCloud services.\nAs the work in Phase II may become classified, it\u2019s worth noting that Cenith Innovations is a domestically owned company.\nNo non-US citizens will participate in this effort.\nWe have no foreign ownership, control, or influence and maintain a TOP SECRET facility security clearance under CAGE 88BH3.\nCurrently, over 80% of our workforce has a SECRET clearance or above, and over 60% has a TOP SECRET, Sensitive Compartmented Information, and/or Special Access Program clearance.\nUse or disclosure of data contained on this page is subject to the restriction on the first page of this volume.\n17",
        "25": "SBIR Phase I Proposal Proposal Number Topic Number Proposal Title Date Submitted Firm Information Firm Name Mail Address Website Address UEI Duns Cage F244-0001-0094 AF244-0001 Faster, Easier, and More Accurate Automated Updating of Dynamic Knowledge Graphs for Intelligence and Operations Using Graph Attention Networks and Update Impact Prediction Networks 11/06/2024 11:30:22 AM Cenith Innovations, LLC 1861 9th Avenue, Sacramento, California, 95818 http://www.cenithinnovations.com ML3NGPZG8PS3 116925606 88BH3 Total Dollar Amount for this Proposal Base Year Year 2 Technical and Business Assistance(TABA)- Base TABA- Year 2 Base Year Summary Total Direct Labor (TDL) Total Direct Material Costs (TDM) Total Direct Supplies Costs (TDS) Total Direct Equipment Costs (TDE) Total Direct Travel Costs (TDT) Total Other Direct Costs (TODC) G&A (rate 35%) x Base (TDL+TOH) Total Firm Costs Subcontractor Costs Total Subcontractor Costs (TSC) Cost Sharing Profit Rate (7%) Total Estimated Cost TABA Year 2 Summary Total Direct Labor (TDL) $139,870.87 $139,870.87 $0.00 $0.00 $0.00 $93,838.84 $4,038.00 $0.00 $0.00 $0.00 $0.00 $32,843.60 $130,720.44 $0.00 -$0.00 $9,150.43 $139,870.87 $0.00 $0.00",
        "26": "Total Direct Material Costs (TDM) Total Direct Supplies Costs (TDS) Total Direct Equipment Costs (TDE) Total Direct Travel Costs (TDT) Total Other Direct Costs (TODC) G&A (rate 35%) x Base () Total Firm Costs Subcontractor Costs Total Subcontractor Costs (TSC) Cost Sharing Profit Rate (7%) Total Estimated Cost TABA Base Year Direct Labor Costs $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 -$0.00 $0.00 $0.00 $0.00 Category / Individual-TR Software Developer/ Principal Investigator (Bryan O'Rourke) Rate/Hour Estimated Hours Fringe Rate (%) Fringe Cost Cost $106.00 100 21.3 $2257.80 $12,857.80 Software Developer/ Senior Software Engineer Life Scientists, All Other/ Research Lead and Reporting Subtotal Direct Labor (DL) Labor Overhead (rate 5.11%) x (DL) Total Direct Labor (TDL) Direct Material Costs AWS GovCloud GPU Time Total Direct Material Costs (TDM) G&A (rate 35%) x Base (TDL+TOH) Cost Sharing Profit Rate (7%) Total Estimated Cost TABA Year 2 Direct Labor Costs $90.00 650 21.3 $12460.50 $70,960.50 $90.00 50 21.3 $958.50 $5,458.50 $89,276.80 $4,562.04 $93,838.84 $4,038.00 $4,038.00 $32,843.60 -$0.00 $9,150.43 $139,870.87 $0.00 Category / Individual-TR Rate/Hour Estimated Fringe Rate Fringe Cost Cost",
        "27": "Software Developer/ Principal Investigator (Bryan O'Rourke) $0.00 0 0 $0.00 $0.00 Hours (%) Subtotal Direct Labor (DL) Labor Overhead (rate 0%) x (DL) Total Direct Labor (TDL) Direct Material Costs None Total Direct Material Costs (TDM) G&A (rate 35%) x Base () Cost Sharing Profit Rate (7%) Total Estimated Cost TABA $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 -$0.00 $0.00 $0.00 $0.00 Explanatory Material Relating to the Cost Volume The Official From the Firm that is responsible for the cost breakdown Name: Aimee Kaiser Phone: (207) 491-3865 Phone: aimee@cenithinnovations.com Title: Proposal Owner If the Defence Contracting Audit Agency has performed a review of your projects within the past 12 months, please provide: No Select the Type of Payment Desired: Partial payments",
        "28": "Cost Volume Details Direct Labor Base Category Description Education Yrs Experience Hours Rate Fringe Rate Total Software Developer Software Developer Principal Investigator Senior Software Engineer Bachelor's Degree Bachelor's Degree Life Scientists, All Other Research Lead and Reporting PhD 10 25 20 100 $106.00 21.3 $12,857.80 650 $90.00 21.3 $70,960.50 50 $90.00 21.3 $5,458.50 Are the labor rates detailed below fully loaded?\nNO Provide any additional information and cost support data related to the nature of the direct labor detailed above.\nCost of labor in line with state averages.\nDirect Labor Cost ($): Year2 $89,276.80 Category Description Education Yrs Experience Hours Rate Fringe Rate Total Software Developer Principal Investigator Bachelor's Degree 10 0 $0.00 0 $0.00 Are the labor rates detailed below fully loaded?\nNO Provide any additional information and cost support data related to the nature of the direct labor detailed above.\nThis is a Phase I effort and labor rates are not calculated for Phase II yet.\nDirect Labor Cost ($): Sum of all Direct Labor Costs is($): Overhead Base Labor Cost Overhead Rate (%) $0.00 $89,276.80 5.11",
        "29": "Apply Overhead to Direct Materials Cost?\nNO Overhead Comments: This is a Phase I effort and labor rates are not calculated for Phase II yet.\nOverhead Cost ($): Year2 Labor Cost Overhead Rate (%) Apply Overhead to Direct Materials Cost?\nOverhead Comments: This is a Phase I effort and rates are not calculated for Phase II yet.\nOverhead Cost ($): Sum of all Overhead Costs is ($): General and Administration Cost Base G&A Rate (%): Apply G&A Rate to Overhead Costs?\nApply G&A Rate to Direct Labor Costs?\nApply G&A Rate to Direct Material Costs?\nPlease specify the different cost sources below from which your company's General and Administrative costs are calculated.\nThis is a Phase I effort and rates are not calculated for Phase II yet.\nG&A Cost ($): Year2 G&A Rate (%): Apply G&A Rate to Overhead Costs?\n$4,562.04 0 NO $0.00 $4,562.04 35 YES YES NO $32,843.60 35 NO",
        "30": "Apply G&A Rate to Direct Labor Costs?\nApply G&A Rate to Direct Material Costs?\nPlease specify the different cost sources below from which your company's General and Administrative costs are calculated.\nThis is a Phase I effort and rates are not calculated for Phase II yet.\nG&A Cost ($): Sum of all G&A Costs is ($): ODC-Materials Base Description: AWS GovCloud GPU Time Vendor: Amazon Quantity: 6 Consumable?\nno Exclusive for this Contract?\nyes Supporting Comments: Supporting Documents: \u2022 MAT 001_AWS GPU Time (1).pdf Year2 Description: None Quantity: 0 Consumable?\nno Total Cost($): $4,038.00 Competitively Sourced?\nyes Vendor: N/A Total Cost($): $0.00 Competitively Sourced?\nno Exclusive for this Contract?\nno Supporting Comments: This is a Phase I effort and costs are not calculated for Phase II yet.\nODC-Summary Base Do you have any additional information to provide?\nYear2 Do you have any additional information to provide?\nNO NO $0.00 $32,843.60 NO NO",
        "31": "Profit Rate/Cost Sharing Base Cost Sharing ($): Cost Sharing Explanation: Profit Rate (%): Profit Explanation: Total Profit Cost ($): Year2 Cost Sharing ($): Cost Sharing Explanation: Profit Rate (%): Profit Explanation: Total Profit Cost ($): Total Proposed Amount ($): - 7 $9,150.43 - 7 $9,150.43 $139,870.87",
        "32": "SBIR Company Commercialization Report CENITH INNOVATIONS LLC DISCLAIMER: Information provided herein is privileged and confidential, and not subject to disclosure, pursuant to 15 U.S.C.\n638 (k)(4) and 5 U.S.C.\n552.\nThis information shall only be used or disclosed for evaluation purposes.\nPrivileged and confidential and not subject to disclosure pursuant to 15 U.S.C.\n638 (k)(4) and 5 U.S.C.\n552.\nLast Updated On: 01/10/2024 Page 1/3",
        "33": "SBIR Company Commercialization Report Total Investments: Total Sales: Total Patents: $0.00 Company Information Address: $0.00 0 1861 9TH AVE SACRAMENTO, CA 95818-4111 United States Government Designated Phase III Funding: $0.00 SBC Control ID: SBC_001616419 Company Url: http://www.cenithinnovations.com Company POC Title: CEO Full Name: Kristopher Pruitt Phone: Email: 9167073178 kris@cenithinnovations.com Additional Company Information % Revenue for last fiscal year from SBIR/STTR funding: 0.0% Year Founded: 2019 Commercialization POC Title: CEO Full Name: Kristopher Pruitt Phone: Email: (916) 707-3178 kris@cenithinnovations.com Total revenue for last fiscal year: $5,000,000 - $19,999,999 # Employees Currently: 32 Year first Phase I award received: # SBIR/STTR Phase I Awards: 2021 4 Year first Phase II award received: # SBIR/STTR Phase II Awards: 2022 3 # Employees at first Phase II award: Mergers and Acquisition within past 2 years: 19 No Spin-offs resulting from SBIR/STTR: IPO resulting from SBIR/STTR | Year of IPO: No No | N/A Patents resulting from SBIR/STTR | #Patents: List of Patents: No | N/A Woman-Owned: No HUBZone-Certified: No Additional Investment From DoD contracts/DoD subcontracts Angel Investors Venture Capital Self Funded Private Sector Other Federal Contracts/Grants Other Sources Additional Investment Total Investment Socially and Economically Disadvantaged: No SBC majority-owned by multiple VCOC, HF, PE firms | By what percent (%): No | N/A Last Submitted Version (01-21-2022 06:34 PM) Current Version $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 Page 2/3 Privileged and confidential and not subject to disclosure pursuant to 15 U.S.C.\n638 (k)(4) and 5 U.S.C.\n552.\nLast Updated On: 01/10/2024",
        "34": "SBIR Company Commercialization Report Phase III Sales To DoD or DoD prime contractors Private Sector Export Markets Other Federal Agencies Additional commercialization by 3rd Party Revenue Other Customers Additional Sales Total Sales Government Phase III Contracts Last Submitted Version (01-21-2022 06:34 PM) Current Version $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 Funding Obligated $0.00 $0.00 Last Submitted Version (01-21-2022 06:34 PM) Current Version Commercialization Narrative Commercialized Awards Listed below are the sales revenue and investment details resulting from the technology developed under these SBIR/STTR awards.\nYou have not entered any Commercialized Award Data.\nPrivileged and confidential and not subject to disclosure pursuant to 15 U.S.C.\n638 (k)(4) and 5 U.S.C.\n552.\nLast Updated On: 01/10/2024 Page 3/3",
        "35": "Aimee Kaiser, Cenith Innovations, LLC Nov 06, 2024 Nov 06, 2025"
    },
    "images": [
        {
            "page": 1,
            "image_file": "docNAC01FB7453538227bb1538cecadff4b852a42eba06482e77570ea14509a56354333e7bc307ef_page1_img1.jpeg",
            "hash": "963c69c169799696",
            "position": "Middle Center"
        },
        {
            "page": 8,
            "image_file": "docNAC01FB7453538227bb1538cecadff4b852a42eba06482e77570ea14509a56354333e7bc307ef_page8_img1.png",
            "hash": "f361c98d0d46d2d6",
            "position": "Top Center"
        },
        {
            "page": 9,
            "image_file": "docNAC01FB7453538227bb1538cecadff4b852a42eba06482e77570ea14509a56354333e7bc307ef_page9_img1.png",
            "hash": "dbe4b735a461c216",
            "position": "Top Center"
        },
        {
            "page": 12,
            "image_file": "docNAC01FB7453538227bb1538cecadff4b852a42eba06482e77570ea14509a56354333e7bc307ef_page12_img1.jpeg",
            "hash": "c941b2ba753788dc",
            "position": "Top Center"
        },
        {
            "page": 13,
            "image_file": "docNAC01FB7453538227bb1538cecadff4b852a42eba06482e77570ea14509a56354333e7bc307ef_page13_img1.png",
            "hash": "bf3cc2c248691d9e",
            "position": "Middle Center"
        },
        {
            "page": 22,
            "image_file": "docNAC01FB7453538227bb1538cecadff4b852a42eba06482e77570ea14509a56354333e7bc307ef_page22_img1.png",
            "hash": "faca9535254bc85a",
            "position": "Middle Center"
        },
        {
            "page": 25,
            "image_file": "docNAC01FB7453538227bb1538cecadff4b852a42eba06482e77570ea14509a56354333e7bc307ef_page25_img1.png",
            "hash": "834987a6cf38ccb6",
            "position": "Top Left"
        },
        {
            "page": 35,
            "image_file": "docNAC01FB7453538227bb1538cecadff4b852a42eba06482e77570ea14509a56354333e7bc307ef_page35_img1.jpeg",
            "hash": "c6cc2b23999bb24d",
            "position": "Middle Center"
        }
    ],
    "firm_info": {
        "company": "N/A",
        "address": "N/A",
        "website": "cenithinnovations.com",
        "name": "N/A",
        "phone": "N/A"
    }
}