{
    "filename": "docNAC01FB7453535f20dd5d3e434380aea996b91e95b0ab1730760eee36fd178dc0180453cf2b0f.pdf",
    "text_by_page": {
        "2": "Small Business Innovation Research(SBIR) Program - Proposal Cover Sheet Disclaimer Knowingly and willfully making any false, fictitious, or fraudulent statements or representations may be a felony under the Federal Criminal False Statement Act (18 USC Sec 1001), punishable by a fine of up to $10,000, up to five years in prison, or both.\nSBIR Phase I Proposal Proposal Number: F244-0001-0048 Proposal Title: IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Agency Information Agency Name: Command: USAF AFMC Topic Number: AF244-0001 Firm Information Firm Name: The Bulls Run Group, Inc Address: Website: UEI: DUNS: CAGE: 9207 Bulls Run Pkwy, Bethesda, MD 20817-2403 https://www.bulls.run KDH9SC281WL8 129524731 8LSH4 SBA SBC Identification Number: 001972933 Firm Certificate OFFEROR CERTIFIES THAT: 1.\nIt has no more than 500 employees, including the employees of its affiliates.\n2.\nNumber of employees including all affiliates (average for preceding 12 months) 3.\nThe business concern meets the ownership and control requirements set forth in 13 C.F.R.\nSection YES 10 YES 121.702.\n4.\nVerify that your firm has registered in the SBAS Company Registry at www.sbir.gov by providing the SBC_001972933 SBC Control ID# and uploading the registration confirmation PDF: Supporting Documentation: \u2022 SBA Registration.pdf",
        "3": "5.\nIt has more than 50% owned by a single Venture Capital Owned Company (VCOC), hedge fund, or private equity firm 6.\nIt has more than 50% owned by multiple business concerns that are VOCs, hedge funds, or private NO NO equity firms?\n7.\nThe birth certificates, naturalization papers, or passports show that any individuals it relies upon to YES meet the eligibility requirements are U.S.\ncitizens or permanent resident aliens in the United States.\n8.\nIs 50% or more of your firm owned or managed by a corporate entity?\n9.\nIs your firm affiliated as set forth in 13 CFR Section 121.103?\n10.\nIt has met the performance benchmarks as listed by the SBA on their website as eligible to participate 11.\nFirms PI, CO, or owner, a faculty member or student of an institution of higher education NO NO YES YES 12.\nThe offeror qualifies as a: [ ] Socially and economically disadvantaged SBC [ ] Women-owned SBC [X] HUBZone-owned SBC [X] Veteran-owned SBC [X] Service Disabled Veteran-owned SBC [ ] None Listed 13.\nRace of the offeror: [ ] American Indian or Alaska Native [ ] Native Hawaiian or Other Pacific Islander [ ] Asian [X] White [ ] Black or African American [ ] Do not wish to Provide 14.\nEthnicity of the offeror: NON- HISPANIC 15.\nIt is a corporation that has some unpaid Federal tax liability that has been assessed, for which all FALSE judicial and administrative remedies have not been exhausted or have not lapsed, and that is not being paid in a timely manner pursuant to an agreement with the authority responsible for collecting the tax liability: 16.\nFirm been convicted of a fraud-related crime involving SBIR and/or STTR funds or found civilly liable NO for a fraud-related violation involving federal funds: 17.\nFirms Principal Investigator (PI) or Corporate Official (CO), or owner been convicted of a fraud-related NO crime involving SBIR and/or STTR funds or found civilly liable for a fraud-related violation involving federal funds: Signature: Printed Name Stoney Trent Signature Title Business Name Date Stoney Trent President The Bulls Run Group, Inc 06/01/2024",
        "4": "Audit Information Summary: Has your Firm ever had a DCAA review?NO VOL I - Proposal Summary Summary: Proposed Base Duration (in months): 6 Technical Abstract: IKOS will build upon recent advancements in knowledge graph extraction to deliver software that will enable analysts to interact with complex multimodal knowledge graphs in a low-effort, intuitive manner.\nWe will do so by leveraging a government off-the-shelf platform, Information Operations Network (ION), for realistic multimodal data.\nWe will orient the functionality of our knowledge graph interactivity on insights gleaned through a campaign of Mission Engineering for Open- Source Intelligence Analysts.\nThese insights will allow us to determine the technical feasibility, acceptability, and suitability of IKOS software that can be delivered within existing and/or emerging analytic support platforms.\nIKOS will improve upon RESIN and RESIN-EDITOR to better support knowledge graph interaction.\nWe will integrate advanced capabilities that allow for automatic fine-grained knowledge completion and real-time knowledge propagation based on user inputs.\nWe will develop the capability to flag logical inconsistencies and conflicts as the analyst interacts with the graph, identify, and localize inconsistencies with analyst-specified domain knowledge.\nWe will develop a new feature that automates schema matching and knowledge graph refinement, to include the ability to suggest additional edges between related nodes, infer new relationships, highlight information gaps, and automatically flag inconsistencies as users interact with the graph.\nWe will implement a natural language interface, allowing analysts to input modifications more intuitively, which will be automatically propagated throughout the graph, ensuring coherence and consistency across all connected data points.\nWe will implement sensitivity analysis that directs analysts\u2019 attention to aspects of the graph that require their revisions.\nFinally, we will adapt approaches to translating expertise into probabilistic parameters to afford analysts the ability to introduce their expert intuition into knowledge graphs.\nAnticipated Benefits/Potential Commercial Applications of the Research or Development: IKOS will significantly enhance current approaches to knowledge graph interaction by enabling dynamic multimodal knowledge graph refinement.\nRather than relying solely on the analyst\u2019s manual input or requiring extensive retraining of underlying models, the system will integrate user corrections, identify contradictions, and adjust the graph\u2019s fine-grained",
        "5": "structure in real-time.\nAs a result, analysts will be able to rapidly complete and refine large-scale, multimodal knowledge graphs without needing to manually track every update and change throughout the graph.\nIKOS will significantly reduce the cognitive burden on analysts, enabling them to focus on higher-order reasoning tasks instead of labor-intensive knowledge management.\nIKOS will provide numerous benefits for intelligence analysis applications, including more accurate and up-to-date situational awareness, improved detection of emerging patterns, and improved decision-making in time-sensitive contexts.\nIKOS will enable analysts to easily refine large complex knowledge structures while enhancing their completeness and consistency.\nIKOS knowledge structures will become an even more practical and robust tool that supports a wide range of intelligence applications.\nIKOS will address key limitations in current state-of-the-art systems, leading to a new generation of dynamic, multimodal knowledge graphs that are not only comprehensive but also agile enough to meet the evolving demands of real-world intelligence analysis environments.\nThe initial focus for IKOS is to deliver capabilities to military intelligence programs of record, beginning with the Command and Control of the Information Environment (C2IE), an analytic platform that provides open-source data as a means of real-time situational awareness.\nIKOS\u2019s multimodal data integration will strengthen C2IE\u2019s capacity to deliver actionable intelligence.\nIn the private sector, IKOS will be positioned as a business intelligence (BI) solution for critical infrastructure firms (e.g., energy providers, financial firms), where real-time insights drive essential decision-making.\nAttention: Disclaimer: For any purpose other than to evaluate the proposal, this data except proposal cover sheets shall not be disclosed outside the Government and shall not be duplicated, used or disclosed in whole or in part, provided that if a contract is awarded to this proposer as a result of or in connection with the submission of this data, the Government shall have the right to duplicate, use or disclose the data to the extent provided in the funding agreement.\nThis restriction does not limit the Government's right to use information contained in the data if it is obtained from another source without restriction.\nThis restriction does not apply to routine handling of proposals for administrative purposes by Government support contractors.\nThe data subject to this restriction is contained on the pages of the proposal listed on the line below.\nAddition: Enter the page numbers separated by a space of the pages in the proposal that are considered proprietary: List a maximum of 8 Key Words or phrases, separated by commas, that describe the Project: Knowledge Graphs, Artificial Intelligence, Cognitive Engineering, Collaborative analysis, Mission Engineering, Intelligence Analysis VOL I - Proposal Certification Summary: 1.\nAt a minimum, two thirds of the work in Phase I will be carried out by your small business as defined by 13 C.F.R YES Section 701-705.\nThe numbers for this certification are derived from the budget template.\nTo update these",
        "6": "numbers, review and revise your budget data.\nIf the minimum percentage of work numbers are not met, then a letter of explanation or written approval from the funding officer is required.\nPlease note that some components will not accept any deviation from the Percentage of Work (POW) minimum requirements.\nPlease check your component instructions regarding the POW requirements.\nFirm POW Subcontractor POW 100% 0% 2.\nIs primary employment of the principal investigator with your firm as defined by 13 C.F.R Section 701-705?\nYES 3.\nDuring the performance of the contract, the research/research and development will be performed in the YES United States.\n4.\nDuring the performance of the contract, the research/research and development will be performed at the YES offerors facilities by the offerors employees except as otherwise indicated in the technical proposal.\n5.\nDo you plan to use Federal facilities, laboratories, or equipment?\n6.\nThe offeror understands and shall comply with export control regulations.\n7.\nThere will be ITAR/EAR data in this work and/or deliverables.\nNO YES YES 8.\nHas a proposal for essentially equivalent work been submitted to other US government agencies or DoD NO components?\n9.\nHas a contract been awarded for any of the proposals listed above?\n10.\nFirm will notify the Federal agency immediately if all or a portion of the work authorized and funded under this proposal is subsequently funded by another Federal agency.\nNO YES 11.\nAre you submitting assertions in accordance with DFARS 252.227-7017 Identification and assertions use, NO release, or disclosure restriction?\n12.\nAre you proposing research that utilizes human/animal subjects or a recombinant DNA as described in DoDI NO 3216.01, 32 C.F.R.\nSection 219, and National Institutes of Health Guidelines for Research Involving Recombinant DNA of the solicitation: 13.\nIn accordance with Federal Acquisition Regulation 4.2105, at the time of proposal submission, the required YES certification template, \"Contractor Certification Regarding Provision of Prohibited Video Surveillance and Telecommunications Services and Equipment\" will be completed, signed by an authorized company official, and included in Volume V: Supporting Documents of this proposal.\nNOTE: Failure to complete and submit the required certifications as a part of the proposal submission process may be cause for rejection of the proposal submission without evaluation.\n14.\nAre teaming partners or subcontractors proposed?\nNO 15.\nAre you proposing to use foreign nationals as defined in 22 CFR 120.16 for work under the proposed effort?\nNO 16.\nWhat percentage of the principal investigators total time will be on the project?\n17.\nIs the principal investigator socially/economically disadvantaged?\n10% NO 18.\nDoes your firm allow for the release of its contact information to Economic Development Organizations?\nYES VOL I - Contact Information",
        "7": "Principal Investigator Name: Dr.\nStoney Trent Phone: (301) 456-4237 Email: stoney@bullsrungroup.com Address: 9207 Bulls Run Pkwy, Bethesda, MD 20817 - 2403 Corporate Official Name: Dr.\nStoney Trent Phone: (301) 456-4237 Email: stoney@bullsrungroup.com Address: 9207 Bulls Run Pkwy, Bethesda, MD 20817 - 2403 Authorized Contract Negotiator Name: Dr.\nStoney Trent Phone: (301) 456-4237 Email: stoney@bullsrungroup.com Address: 9207 Bulls Run Pkwy, Bethesda, MD 20817 - 2403 Form Generated on 11/05/2024 05:16:53 PM",
        "8": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Volume 2: Technical Volume 1.\nIdentification and Significance of the Problem a.\nCurrent state of Open-Source Intelligence (OSINT) analysis.\nOSINT has traditionally been the province of federal military and intelligence organizations (Williams & Blum, 2018).\nHowever, as an increasingly large share of human behavior becomes technologically mediated and made accessible on social media and other platforms, the tools, techniques, and procedures of government OSINT have been adopted and expanded by non-government organizations (NGOs) and the private sector, including journalists, human rights advocates, and private investigators (Dubberley et al., 2019).\nAlthough traditional intelligence analysis has been dominated by individual efforts with a strong sense of ownership, and intelligence agencies have been criticized for a lack of cooperation, these new forms of OSINT are increasingly social in nature (Belghith et al., 2022).\nSome even leverage expertise from both public and private entities.\nOSINT Challenges \u2022 Massive amount of multi-modal Contemporary OSINT often emerges as \u201cexpert-led crowdsourcing,\u201d with lead analysts managing a framework for contributions from professionals and hobbyists.\nThe CrowdSolve project brought together detectives, forensics experts, and over 200 true crime enthusiasts to spend a weekend reviewing case files to make progress in two cold cases (Venkatagiri et al., 2021).\nSedition Hunters, an OSINT community organized on Twitter, has contributed evidence cited in several FBI arrest warrants for suspects in the January 6th US Capitol riot (Yu et al., 2023).\nTrace Labs, a Canadian non-profit, partners with law enforcement to conduct crowdsourced OSINT investigations of missing persons, structured as a Capture-the- Flag competition where teams (including US military personnel (Stover, 2019)) earn points for collecting relevant evidence.\nThese successful examples, where officials define investigation targets and/or directly supervise the crowd\u2019s efforts, contrast with prominent failures of \u201cdigilantes\u201d that result in misidentified suspects, as in the 2013 Boston Marathon Bombing (Nhan et al., 2017) and the 2017 Charlottesville white nationalist rally (Victor, 2017).\ndata Increasingly crowd-sourced and performed by non-government groups Team efforts involving variety of expertise Information about process is important for accurate judgments about rigor Includes a variety of objectives, approaches, and mindsets \u2022 \u2022 \u2022 \u2022 In the last twenty years, cognitive engineering research has documented challenges for intelligence analysis.\nSome of these challenges apply to IKOS.\nFor example, Zelik, Paterson, and Woods (2007a), found that professional intelligence analysts make better judgments about analytic rigor of reports when provided with information about the analytic process.\nTrent, Patterson, and Woods (2007) observed that intelligence analysis is typically performed by teams comprising modestly skilled analysts who are supervised by a more experienced analyst.\nThis conveys the importance of designing to support teamwork and supervision rather than individual work.\nStraus, Parker, and Bruce (2011) found that analysts struggle with polarization, overconfidence, and pressures toward uniformity.\nResearch in Team Cognition has determined that introducing new technologies does not necessarily improve performance on complex cognitive tasks.\nCollectively, the corpus of research suggests that a one-size-fits-all AI model might be unhelpful or counterproductive.\nKnowledge graphs offer ways to accommodate information sharing across a variety of analytic objectives, approaches, and mindsets.\nb.\nCurrent state of knowledge graphs supporting collaborative analysis.\nKnowledge graphs represent concepts about the world in an interpretable structure (Hogan et al.\n2021).\nBecause of their ability to capture higher-level real-world knowledge in a human and machine-understandable representation, knowledge graphs have found broad downstream applications, including question answering (Ding et al.\n2022), financial forecasting (Liu et al.\n2019), image understanding (Aditya et al.\n2019), and future event prediction (Li et al.\n2021).\nIn our own work, we have leveraged knowledge graphs for intelligence- related tasks such as identifying anomalous human movement (Bavikadi et al., 2024), predicting cyber attacks Page 1 of 34",
        "9": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 (Sarkar et al., 2019), and detecting, attributing, and characterizing disinformation (Fung et al., 2021).\nIdeally, knowledge graphs are derived from reliable data or an overarching theoretical framework, which determine the conditions and hypotheses under which the model is valid or \u201ctrue\u201d.\nHowever, these models are only useful insofar as analysts can effectively interpret the model outputs, identify their limitations, and apply new knowledge or human expertise to improve on the models\u2019 capabilities and representations.\nProviding analysts with information about the limitations of these models and the knowledge graphs they Knowledge Graph Challenges o Difficult to interpret and update o KG limitations are often hidden o Most extraction methods are limited to produce is challenging.\nA model may have incorrect parameters, the chosen values may not be good approximations of reality, or the knowledge graphs may be derived from noisy or incomplete data.\nResearchers often refer to this challenge as \"The Black Box Menace,\" where the behavior and impact of model inputs or parameters are unknown and can propagate uncertainty during analysis.\nBegoli, Bhattacharya, and Kusnezov (2019) highlight the issue that the \"absence of theory\" in purely data- driven models often makes proper uncertainty quantification an essential ingredient\u2014even if the model behavior cannot be explicitly understood, the propagation of uncertainty and sources of uncertainty in the model inputs and outputs can be understood.\nHowever, simply highlighting the sources of uncertainty in a model only provides insight into how reliable or useful the model may be in certain contexts.\nIt does not provide analysts with the tools necessary to improve and update the model to increase its overall efficacy.\nrely on visual detectors trained offline on supervised data o Multimodal knowledge representations text Even capturing relevant knowledge and encoding it in a graph remains challenging.\nSeveral human- curated knowledge graph resources, such as Wikidata (Vrande\u010di\u0107 et al.\n2014) and Freebase (Bollacker et al.\n2008), have been created, but such approaches are very expensive to create, may not translate well to new domains, and often suffer from incompleteness (Zhang et al.\n2018).\nAutomated knowledge induction methods relying on text information extraction have also been proposed (Mausam et al.\n2016), but such methods may be prone to many types of errors, such as incorrect information extraction output and failures in entity resolution (Gupta et al.\n2019).\nSeo et al.\n(2021) leverage active learning techniques to expand and refine a knowledge graph from text, but do not attempt to refine a multimodal knowledge graph.\nc.\nCurrent state of Multimodal Knowledge Graph Creation and Interaction Capabilities.\nMost recent approaches to knowledge graph creation involve deep learning methods to learn graph embeddings that capture the meaning of relations (e.g.\nsemantic relations, temporal ordering, and others) between entities within the graph (Fung et al.\n2021; Zhang et al.\n2021).\nSuch embeddings are typically used to initialize a graph neural network, which is then trained to perform the downstream task of interest (Kato et al.\n2018; Fung et al.\n2021; Marino et al.\n2017).\nWhile there has been some recent work in representing multimodal knowledge about activities in structured graphs (Li et al.\n2020; Li et al.\n2022; Wen et al.\n2021; Chen et al.\n2021), most knowledge graph extraction methods work purely on text.\nExtracting multimodal knowledge graphs remains a very challenging problem because it requires a fine-grained understanding of how knowledge from one modality relates to data from a different modality (e.g.\nwhat is the relationship between a particular entity in an image with a word in text or a location on a map).\nAt a minimum, knowledge graphs incorporating visual data require being able to detect relevant visual content (e.g., objects or events) and then ground it to appropriate points within the graph.\nAutomated visual understanding capabilities are limited, however, and if the appropriate objects are not able to be detected, the relevant multimodal links will not be discovered.\nHowever, most existing methods for multimodal knowledge representation rely on visual detectors trained offline on supervised data (Li et al.\n2020, Wen et al.\n2021).\nThus, knowledge graphs extracted by such systems are often incomplete and have some amount of noise.\nPage 2 of 34",
        "10": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 Recent advances in artificial intelligence and information extraction have enabled the construction of sophisticated multimodal knowledge graphs (KGs) that capture structured representations of entities, events, and their relationships across diverse data sources.\nA general depiction of the functions comprising KG extraction can be found in Figure 1.\nToday, graphs go beyond traditional text-based representations, integrating information from multiple modalities such as visual, audio, geospatial, and temporal sources (Ma et al.\n2022, Liang et al.\n2024, Wilcke et al.\n2023).\nBy linking entities and events across these various data sources, such knowledge graph extraction systems provide a comprehensive and contextualized view of complex real-world scenarios (Wen et al.\n2021, Du et al.\n2022).\nThis multimodal fusion supports a range of applications, including situational awareness, event prediction (Li et al.\n2021), and intelligence analysis, by offering decision-makers a detailed and interpretable structure of interconnected facts and relationships (Rajabi et al.\n2024).\nFigure 1 \u2013 Multimedia, Entity-Centric Knowledge Extraction.\nAdapted from Zhong et al.\n(2023).\nA suite of techniques to learn the types, links, and relations between entities.\nDespite their promise, these existing systems face significant challenges when dealing with dynamically evolving and incomplete knowledge.\nMultimodal knowledge graphs often contain gaps or errors due to limitations in the initial extraction process, the inherent uncertainty of multimodal data, or changes in the real-world environment that render previously extracted information outdated (Wang et al.\n2024, Cheng et al.\n2024).\nAddressing these issues through manual corrections is not only labor-intensive but also impractical at scale, especially for large, complex knowledge graphs used in operational environments.\nMoreover, many existing systems (Wen et al.\n2021, Du et al.\n2022) lack the ability to automatically detect non-obvious inconsistencies within the graph and adjust their representations based on new human input.\nThis creates a need for methods that allow analysts to refine and update knowledge structures efficiently and in so doing, minimizing the cognitive and time burden on users.\nKnowledge graph refinement is a broad term that encompasses a range of methods aimed at improving the accuracy, completeness, and quality of knowledge graphs.\nThis process includes various sub-tasks such as error correction, schema alignment, and knowledge graph completion.\nRefinement involves adding, modifying, or removing facts and relationships to keep the graph up-to-date, correct inaccuracies, and resolve conflicts between entities (Subagdja et al., 2024).\nWhile some early refinement methods relied heavily on manual adjustments, modern approaches increasingly leverage automated techniques, such as machine learning models and rule-based algorithms, enabling large-scale, dynamic graphs to adapt rapidly to new information (Subagdja et al., 2024).\nThis automation is particularly useful in fast-paced contexts like military intelligence, where rapid adjustments and high accuracy are crucial.\nWithin the broader process of KG refinement, knowledge graph completion specifically focuses on predicting and filling in missing information within the graph (Shen et al.\n2022).\nCompletion techniques use the existing structure and relationships in the KG to infer new connections between entities (Wang et al.\n2022).\nBy employing methods like graph embeddings, completion models can identify plausible links based on Page 3 of 34",
        "11": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 the graph\u2019s topology (Lin et al, 2023).\nWhile completion enhances the comprehensiveness of the graph by addressing gaps, it is primarily geared toward symbolic graphs (Chen et al.\n2022) and faces challenges when applied to multimodal data (Chen et al.\n2022).\nThe presence of diverse data types and complex cross-modal relationships makes it difficult to generate accurate inferences consistently without introducing noise or errors.\nWhile refinement and completion methods are helpful in creating richer and more accurate multimodal knowledge graphs, most existing systems are not designed to integrate human input with these automated processes.\nCurrent methods either rely on specialized interfaces that require users to manually manipulate the graph\u2019s structure (Ilievski et al.\n2020), depend on models that are inflexible to new types of multimodal knowledge, either requiring few-shot examples (Zhang et al.\n2022, Li et al.\n2024), or process different modalities independently (Chen et al.\n2023).\nThese sources of rigidity create bottlenecks that are incompatible with work that requires rapid, real-time updating.\nFurther, these methods lack mechanisms for effectively surfacing deeper, cross-modal logical inconsistencies or resolving internal contradictions that arise from newly incorporated data or human edits.\nThis reduces the trust analysts place in these systems and diminishes their purpose of providing human-interpretable structures in operational scenarios that require high- confidence reasoning and decision support.\nFurther, current methods for refinement and completion lack the ability to allow domain knowledge from intelligence analysts to be directly entered into the system.\nFor example, an analyst may see a connection made between rival criminal groups in a given area of interest, and the analyst want to prevent such connections from being automatically inferred, or at least have them flagged as requiring further examination.\nAlong those lines, certain results with respect to knowledge graph KG InteractionShortcomings Low flexibility for analysts o Extensive manual effort o Rely on specialized tools and interfaces o o Poor generalization to multimodal data o Rely on inflexible pre-trained models o o Inefficient integration of human inputs lack mechanisms to identify or resolve logical inconsistencies and contradictions completion may require explanation to the analyst team \u2013 as the team may debate the conclusion drawn by the algorithm.\nHere, the team gains benefit from knowing the algorithmic provenance of a system-performed completion.\nIn our experience in deploying real-world cyber security systems as a result of the IARPA CAUSE program (e.g., see Almukaynizi et al., 2017 which resulted in\u201d CYR3CON\u201d - a commercial offering used by over 80 paying customers) we found that intelligence analysts working at multiple Fortune 500 companies required product features that provided provenance of algorithmically- concluded evidence.\nd.\nRESIN - A Multimodal Knowledge Graph Extractor Recent DARPA projects have advanced the field of multimodal knowledge extraction and knowledge graph creation through an evolving series of systems.\nThe GAIA knowledge extraction system (Li et al.\n2020), developed as part of the DARPA AIDA program, marked an initial step toward creating structured multimodal knowledge graphs.\nGAIA integrates data from multiple modalities\u2014text, visual, and audio\u2014using a human-built ontology to link entities mentioned in text to visual regions, extract event information, cluster coreferential entities, and incorporate external knowledge from sources like Wikipedia.\nImportantly, GAIA supports the generation of alternative hypotheses, allowing analysts to explore different perspectives on complex topics by interacting with the automatically extracted graph (Li et al.\n2020).\nHowever, GAIA is limited by its reliance on conventionally trained, static object detectors and grounding methods.\nWhile it excels at integrating multimodal data, its components are less adaptable to dynamically evolving knowledge and real-world complexity.\nRecognizing these challenges, researchers in the DARPA KAIROS program introduced RESIN (Du et al.\n2022), an extension of GAIA designed to enhance its ability to process and understand complex events more effectively.\nRESIN refines GAIA\u2019s components and incorporates advanced techniques to handle open-world data and addresses several GAIA\u2019s shortcomings.\nConsequently, knowledge graphs constructed by RESIN support more robust event representations and afford deeper cross-modal reasoning.\nPage 4 of 34",
        "12": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 As depicted in Figure 2, RESIN preprocesses and stores multimedia data to extract knowledge graphs.\nBecause there are potentially many pieces of media about the same event or subject, connections between media are specified in a simple TSV file format to associate multiple documents, images, video, with one another.\nOnce the data has been preprocessed, a single docker command is issued which points the system to the folder from which to extract a knowledge graph.\nThis command begins by running several natural language processing dockers for preprocessing the text, running entity and event extraction, linking coreferential events and entities, and predicting the relationships between entities and events.\nThese results are formulated into a text-only knowledge graph.\nNext, the system invokes the dockers for visual knowledge extraction.\nThese systems extract visual knowledge, such as objects and faces, in addition to recognizing buildings, flags, and well- known public figures, as well as event-centric visual knowledge, such as the event shown, its arguments, and semantic roles.\nThese results are stored in a visual knowledge base.\nFinally, cross-media fusion links the two knowledge graphs together to form a multimodal knowledge graph.\nIE \u2013 information extraction framework ASR \u2013 Automated Speech Recognition Qnode \u2013 wikidata identifier Figure 2 - RESIN \u2013 a multimodal knowledge graph extraction system from Du et al.\n(2022).\nThe RESIN system constructs a multimodal knowledge graph by integrating data from text, speech, images, and video.\nRESIN-EDITOR, depicted in Figure 3, provides an interactive platform that allows users to explore hierarchical knowledge structures extracted from multimedia and multi-document data (Nguyen et al.\n2023).\nThrough this interface, analysts can visually track knowledge and their relationships, inspect temporal links, and trace the provenance of each piece of knowledge back to its source document.\nThe tool further supports schema-guided event prediction, so users can understand both observed events and potential next steps based on hierarchical schemas.\nAdditionally, RESIN-Editor supports editing features which enable users to modify nodes, relationships, and temporal structures directly within the graph.\nThis level of interaction allows users to not only correct AI/ML-extracted data but also to refine the graph in real-time for a more accurate and detailed situational analysis.\nUnfortunately, RESIN-Editor does not support natural language inputs or automatic fine-grained graph refinement, knowledge graph completion or inconsistency detection, which makes it less suited for OSINT analysis.\nPage 5 of 34",
        "13": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 Figure 3 - The RESIN-Editor interface (Nguyen et al.\n2023) - an interactive platform that allows users to explore hierarchical knowledge structures extracted from multimedia and multi-document data IKOS co-PI, Dr.\nThomas has extended the foundational technologies in RESIN by integrating more powerful multimodal large language models (LLMs) in place of several key RESIN components to support open-world fine- grained reasoning within complex knowledge structures (Tang et al.\n2024).\nA key strength of this recent work is its ability to extract and organize multimodal knowledge from diverse sources\u2014including text, images, video, and audio\u2014into a structured knowledge graph which supports fine-grained logical inferencing (See Figure 4).\nThese capabilities are essential for constructing fine-grained and accurate knowledge graphs and provide a solid foundation for IKOS.\nThe extraction process leverages a suite of cross-document and cross-media co-reference resolution and advanced entity linking methods to merge disparate sources into a unified, fine-grained representation.\nHaving such well-integrated representations is critical when analysts introduce new inputs or modify existing nodes, as it enables the system to accurately propagate that new information throughout the graph to maintain a coherent structure as the graph is refined.\nIn addition, Thomas has already developed and deployed interactive visualizations of the multimodal knowledge graphs extracted using their system on the web as a feature of an article in Columbia Engineering Magazine, \u201cWhen Trust is a Factor\u201d.\nMagazine readers were able to interact and explore a knowledge graph extracted from a set of multimedia using Thomas\u2019s system (Currin et al.\n2023).\nFigure 4 - Extracting multimodal knowledge structures from collections of multimedia data about an event (Tang et al.\n2024) Page 6 of 34",
        "14": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 Building on these extraction capabilities, Dr.\nThomas has developed a system for multimodal fine-grained logical reasoning and consistency checking (Tang et al.\n2024, Chen et al.\n2024).\nThis system facilitates detailed logical inferences between elements of the knowledge graph and a graph extracted from a claim (See Figure 5).\nAlthough initially designed to generate and verify entailment or contradiction labels extracted for claims for fact-checking, these core techniques can be adapted to support the proposal\u2019s objective of dynamically updating interactive knowledge graphs.\nSpecifically, the fine-grained reasoning models can be employed to automatically infer new knowledge, identify, and resolve contradictions, and complete missing logical links in response to user modifications within the knowledge graph.\nThus, user edits to the knowledge graph would trigger automated updates across related nodes and edges, ensuring logical consistency, highlighting information gaps, and suggesting additional changes to maintain coherence.\nFor example, the current fine-grained logical generation approach presented in Tang et al.\n(2024)\u2014originally developed to synthesize logically consistent or contradictory claims based on multimodal evidence\u2014can be adapted to support fine-grained knowledge graph completion.\nThis would enable the system to proactively suggest additional logical connections or detect inconsistencies when new nodes or edges are introduced.\nThe ability to handle fine-grained logical relationships within a graph, combined with the capacity to extract cross-modal knowledge, supports the development of our interactive knowledge environment.\nFigure 5 \u2013 Fine-grained logical consistency checking (Tang et al.\n2024) Reasoning models are employed to automatically infer new knowledge, identify, and resolve contradictions, and complete missing logical links in response to user modifications Another relevant open-source knowledge-graph capability is PyReason.\nThe PyReason framework was developed by IKOS key person (Shakarian) and allows for reasoning on large knowledge graphs based on logic programming (Aditya et al., 2023).\nWith the PyReason framework, an analyst can express domain knowledge in a PROLOG-like logical language (which can also be created via LLM conversion from natural language).\nThis enables efficient identification of inconsistencies of algorithmic-created extensions with domain knowledge (Shakarian and Simari, 2022) in a manner that provides the user a detailed account as to why the algorithmic-induced inconsistency contradicts the domain knowledge.\nLikewise, the PyReason framework will be able to infer conclusions as combinations of domain-knowledge and algorithmically-induced knowledge.\nThis way the analyst can gain an understanding as to what are the outcomes that a given piece of algorithmically-extended knowledge implies.\nPage 7 of 34",
        "15": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 In short, there have been great advancements in knowledge graphs and knowledge graph interactions recently, and the IKOS team includes leading experts who have delivered these innovations.\nIKOS will build on these recent advancements to deliver on several operationally meaningful technical objectives.\n2.\nPhase I Technical Objectives Intelligence analysts require better capabilities for building, inspecting, editing, and sharing multimodal knowledge graphs.\nWorking in teams, with time sensitive workflows, these analysts require intuitive mechanisms to process and leverage very large relational datasets.\nIKOS will enable intelligence analysts to interact with complex multimodal knowledge graphs in a low-effort, intuitive manner.\nIKOS will significantly enhance the current approaches to knowledge graph interaction by enabling dynamic multimodal knowledge graph refinement.\nRather than relying solely on the analyst\u2019s manual input or requiring extensive retraining of underlying models, the system will integrate user corrections, identify contradictions, and adjust the graph\u2019s fine-grained structure in real-time.\nAs a result, analysts will be able to rapidly complete and refine large-scale, multimodal knowledge graphs without needing to manually track every update and change throughout the graph.\nIKOS will support natural language inputs, allowing analysts to add or update information using simple textual commands or, if they so choose, by visually modifying relevant parts of the graph.\nThe semantic and logical effects of these updates will propagate throughout the graph structure, enabling real-time refinement of the graph\u2019s content and schema without extensive manual intervention.\nFurther, we will allow the analyst to directly input domain knowledge into the system not only in the form of graphical components (e.g., nodes, edges, and their labels) but also logical relationships among entities exhibiting certain characteristics (e.g., two members of rival groups cannot have \u201cfriend\u201d relationship between them).\nIKOS will infer new relationships based on the analyst\u2019s modifications and entered domain knowledge, automatically deriving appropriate conclusions, and identifying potential logical inconsistencies or conflicts with the newly added information.\nFor the case in which inconsistencies are identified with domain knowledge, IKOS shall provide an explainable trace to localize the source of the inconsistency in a manner understandable to the user.\nIKOS will significantly reduce the cognitive burden on analysts, enabling them to focus on higher-order reasoning tasks instead of labor-intensive knowledge management.\nIKOS will provide numerous benefits for intelligence analysis applications, including more accurate and up-to-date situational awareness, improved detection of emerging patterns, and improved decision-making in time-sensitive contexts.\nIKOS will enable analysts to easily refine large complex knowledge structures while enhancing their completeness and consistency.\nIKOS knowledge structures will become an even more practical and robust tool that supports a wide range of intelligence applications.\nIKOS will address key limitations in current state-of-the-art systems, leading to a new generation of dynamic, multimodal knowledge graphs that are not only comprehensive but also agile enough to meet the evolving demands of real-world intelligence analysis environments.\nIn Phase 1, we will obtain baseline performance metrics for our use case with a convenience sample experienced OSINT analysts.\nWe will then evaluate the effects of our proposed approaches to answer the following questions and select the most promising features to develop in Phase 2.\n1) Which IKOS features (See Figure 6 below) to RESIN can be implemented to support OSINT analysis?\n2) Which IKOS features will improve OSINT analysis involving large, complex knowledge graphs?\n3.\nPhase I Statement of Work a.\nScope.\nAs shown in Figure 6, IKOS will build upon recent advancements in knowledge graph extraction to deliver a prototype for an interactive knowledge graph.\nIn Phase 1, we will: 1) 2) Initiate a campaign of Mission Engineering for Open-Source Intelligence Analysis to orient the design and feasibility assessments of IKOS; leverage a government off-the-shelf platform, Information Operations Network (ION), to acquire realistic multimodal data for an OSINT use case; Page 8 of 34",
        "16": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 3) employ an open-source knowledge extraction system (RESIN) to generate an initial knowledge graph for our analytic use case; and 4) enhance RESIN and RESIN-EDITOR with interactivity features to support team curation of knowledge graphs.\nFigure 6 - IKOS Concept.\nWe will leverage a GOTS data repository (ION) and extend upon an open-source application (RESIN) to deliver an interactive support tool for OSINT analysts.\nIKOS will deliver novel support for knowledge graph interaction.\nWe will integrate advanced capabilities that allow for automatic fine-grained knowledge completion and real-time knowledge propagation based on user inputs.\nWe will develop new features that automate schema matching and knowledge graph refinement, to include the ability to suggest additional edges between related nodes, infer new relationships, highlight information gaps, and automatically flag inconsistencies as users interact with the graph.\nWe will implement a natural language interface, allowing analysts to input modifications more intuitively, which will be automatically propagated throughout the graph, ensuring coherence and consistency across all connected data points.\nWe will implement sensitivity analysis that directs analysts\u2019 attention to aspects of the graph that require their revisions.\nFinally, we will adapt approaches to translating expertise into probabilistic parameters to afford analysts the ability to introduce their expert intuition into knowledge graphs.\nb.\nTask Outline.\nWe propose the following five tasks to deliver IKOS and set the conditions for a successful Phase 2 effort to build upon our Phase 1 prototype.\nTask 1 | Mission Engineering We will constitute an interdisciplinary Mission Engineering team, which will employ mixed ethnographic methods, to develop a deep understanding of the current and anticipated needs for knowledge graph interaction amongst open-source intelligence analysts.\nThis campaign, as illustrated in Figure 7, will yield user experience needs, user and work models, and use cases for the new envisioned system.\nThe IKOS field study will directly drive design specifications by generating user interface design improvements for RESIN-Editor, commercialization plans, and a system architecture to support transition.\nIKOS will build on progress and relationships from AFRL RAINFLY, which is a project to deliver a cognitive- psychology informed planning tool for information operations.\nFor RAINFLY, BRG has established relationships with open-source intelligence workgroups, such as the 123rd Intelligence Squadron and 288th Operations Support Squadron in the 188th ISR Group (Arkansas Air National Guard).\nThrough this and other connections to Page 9 of 34",
        "17": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 operational OSINT workgroups, we will accelerate the knowledge elicitation required to support IKOS.\nBRG has also established a dialogue with the Command and Control of the Information Environment (C2IE) program office.\nC2IE is a platform for collecting and analyzing publicly available information and is a likely transition partner for IKOS.\nFigure 7 - Mission Engineering \u2013 a deliberate campaign engaging OSINT analysts and system designers to ensure IKOS is useable, useful, and can be transitioned to a program of record Task 1.1 | Design UI/UX The objective of this sub-task is to generate interactive user interface (UI) designs to enable intuitive, efficient user experiences for OSINT analysts.\nThese designs will accelerate user experience research and inform the application development in Phase II.\nWe propose to extend on the RESIN-EDITOR user interface by designing visualization tools and enabling users to interactively modify knowledge graphs constructed from multimodal data.\nUsers will be able to directly add, delete, or modify nodes and edges representing entities, events, or relationships.\nThe interface will also include rich visualizations of the knowledge graph, with different data modalities (text, images, videos, etc.) linked to specific nodes.\nThis will provide users with an integrated view of the data, ensuring that all modalities are represented and connected in a single knowledge structure.\nIn Phase I we will develop mock-ups and high-level interface designs to support the development of clickable wireframes showing the functionality of the envisioned system for the scoped set of targeted users, with special attention to accessibility options, including color blind.\nWe will employ a user-centered design (UCD) approach (ISO 13407, 1999; Greenbaum & Kyng, 1991; Schuler & Namioka, 1993; Beyer & Holtzblatt, 1998), grounding the process in user needs, expectations, and limitations, to focus on the design of a complete end-to-end workflow.\nThe UCD approach is founded on an iterative cycle of design, user feedback, and revision that not only requires designers to analyze and envision the way users are likely to use a product or service, but also to validate their assumptions with actual users.\nWe will also leverage recent work from the human-computer interaction (HCI), computer supported cooperative work (CSCW), and intelligent user interfaces (IUI) research communities, focusing on theories, frameworks, and design considerations for supporting collaborative sensemaking and analysis, including crowdsourcing, collective intelligence, and human-AI teaming approaches.\nPage 10 of 34",
        "18": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 Task 1.2 | Design System Architecture This sub-task will entail the design of the system architecture to afford scalability, reliability, and security.\nWe will review RESIN and C2IE architectures to better understand how IKOS will need to operate if transitioned to C2IE.\nIn parallel, we will design the architecture with requirements elicited through field study.\nFor the back end, we envision a microservices architecture that allows for components to be developed, tested, and integrated independently.\nIKOS will incorporate a scalable and secure reference architecture for front-end UI application development and AI/ML services development.\nThe initial architecture will serve as the baseline to accommodate the design and deployment of future workflows.\nThis design will leverage the latest in compute, storage, transport, and datastore configurations \u2014 suitable for current and future AI development.\nUsing AWS or other cloud providers, we will create a modular open-system architecture to support rapid prototyping resource-intensive AI services.\nTask 1.3 | Transition and Commercialization Planning This sub-task will set the conditions for transition and commercialization.\nAs noted previously, we will extend on our previous work for AFRL RAINFLY to determine a transition pathway for IKOS into C2IE.\nThis will include coordinating with C2IE requirements owners (A35), to document future IKOS capabilities as requirements for the C2IE roadmap.\nThis will help secure funding in future years for system integration.\nWe also anticipate IKOS will have value in non-defense industries, such as business intelligence.\nBusiness intelligence is an increasingly lucrative form of open-source intelligence.\nCurrent platforms only aggregate, sort, and display data from a variety of feeds.\nNone incorporate knowledge graph structures to assist with more nuanced analysis.\nWe will investigate the funding and technical pathways to deliver IKOS as a licensed feature or service within one or more existing platforms and/or developing a new business intelligence platform with interactive knowledge graphs as a core value proposition.\nThe outputs of this sub-task will be a comprehensive, phased transition and/or commercialization plan to be pursued in Phase 2.\nTask 2 | Multimodal Data Acquisition We will leverage the Information Operations Network (ION), an Army Training and Doctrine Command (TRADOC) G-2 platform for realistic data for the development and testing of IKOS.\nION is a simulated internet with replicated social media and other websites including deep and dark web.\nION has provided analysts with realistic multi-modal data in over 400 intelligence and information operations exercises in the last two years (including 47 USAF events).\nAs such, it is an ecologically valid sandbox of representative data with an ecosystem of intelligence and information operations users.\nThis platform supports simple and complex challenge problems for individuals and teams of multiple open-source intelligence analysts.\nThe ION program office pushes regular updates to this platform to include new data sets and has agreed participated in previous AFRL and ARL research programs.\nWe will coordinate for free access to an unclassified instance of ION in Month 1 of this project.\nTask 3 | Generate Initial Knowledge Graph We will leverage the core components of the RESIN system (Wen et al.\n2021), including relation prediction, event extraction, and argument extraction, cross-media fusion, etc.\nas the foundation for our knowledge graph extraction.\nWhere newer methods\u2014such as enhanced entity recognition, coreference resolution, and cross-modal relation prediction\u2014offer better performance, we will integrate such components from our recent multimedia knowledge graph extraction system (Tang et al.\n2024) to improve overall knowledge graph quality and minimize erroneous extractions.\nWe will also allow for the input of user-created domain knowledge via PyReason \u2013 residing as a layer on top of RESIN to allow for explainable identification and localization of inconsistencies with respect to domain knowledge.\nThe textual pipeline processes both text-based media sources and transcribed audio.\nIt starts with information extraction to extract entities, relations, and events.\nNext, cross-document entity and event coreference resolution links related entities and events across sources, creating a cohesive knowledge representation.\nThis is further enriched by predicting higher-level semantic relations like temporal and causal links.\nFor audio data, we use Qwen-Audio (Chu et al.\n2023) to extract relevant Page 11 of 34",
        "19": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 knowledge from audio signals, along with Whisper (Radford et al.\n2023) to transcribe speech into text, ensuring complete integration of spoken information into the knowledge graph.\nFor images and video, we use a state-of-the-art multimodal large language model (Ye et al.\n2024) to create grounded event structures.\nVisual content is first converted into detailed captions, which are then transformed into dense knowledge structures that include objects, events, and relationships.\nCross-modal coreference resolution and relationship prediction then integrate this visual data with the text-based knowledge graph to form a comprehensive multimodal graph.\nOnce the multimodal graph is constructed, we use a hierarchical schema repository to align extracted information with matching schemas.\nThis guides the final integration and structuring of the multimodal knowledge graph.\nSee Figure 2 for an illustration of the knowledge graph extraction process in RESIN.\nRESIN is fully Dockerized, publicly accessible, and readily deployable on day one.\nBy the end of this task, we will generate comprehensive semantic multimodal knowledge graphs from unstructured intelligence media assets which will then be refined through human interaction in later tasks.\nTask 4 | Develop Interactive Knowledge Graph Features This task represents the core of the research to be performed in IKOS.\nIn this task, we will build upon the open-source code bases for RESIN, RESIN-EDITOR, and PyReason to deliver a minimally functional version of IKOS that supports an OSINT use case.\nFigure 8 illustrates the six features that will 1) improve graph refinement, 2) afford natural language interaction, and 3) improve usability.\nThe following sub-tasks describe how each of these features will be implemented.\nFigure 8- IKOS improvements upon RESIN Task 4.1 | Implement natural language interaction In this sub-task, we will develop two forms of user interaction.\nFirst, users will be able to directly query the knowledge graph, view the results, make manual edits, and augment with analyst domain knowledge.\nWhile this provides full control, manually finding and editing relevant nodes and edges can be time-consuming and cumbersome, especially when analysts need to navigate large, complex graphs.\nTherefore, we also propose to implement a second, more intuitive form of interaction leveraging natural language-based graph editing.\nUsers will input free-form text to express their intended modifications to the graph, and our system will automatically translate these instructions into corresponding graph operations.\nFor example, a user could enter a command such as: \"Update the location of Agent X to Berlin and note that they are now carrying a briefcase.\" This input will be processed using a state-of-the-art large language model (LLM) such as Qwen-2.5 (Yang et al., 2024) or LLaMA 3.1 (Dubey et al., 2024) which will parse the text and translate it into a series of structured actions, such as: 1) Modify Node: Update the 'location' attribute of the node representing 'Agent X' to 'Berlin'; 2) Add Attribute: Add a new attribute 'carrying' with the value 'briefcase' to the node representing 'Agent X'; etc.\nThese proposed changes to the graph in a visual form Page 12 of 34",
        "20": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 will be presented back to the user for confirmation before they are applied to the knowledge graph, allowing the user to review and refine the actions if necessary.\nThe system will also allow for further clarification in natural language to allow the user to further fine-tune the changes to be made.\nTechnically, integration of the LLM with the knowledge graph system will involve several steps.\nFirst, the LLM will process the user's input to identify intent, entities, attributes, and relationships mentioned.\nExtracted elements will be mapped to existing nodes and edges within the knowledge graph, considering coreferential edges within the graph.\nNext, the LLM will generate a sequence of graph operations that reflect the user's intent, following the schema and constraints of the knowledge graph.\nFinally, before executing the actions, the system will display the interpreted operations to the user for validation.\nOur proposed natural language interface will provide a more efficient and user-friendly way to interact with the knowledge graph, especially in scenarios where manually navigating and editing the graph is impractical.\nBy providing two complementary methods for interaction\u2014direct manipulation and natural language input\u2014our system will allow analysts to choose the interaction mode that best suits their needs.\nMoreover, our design positions us to test and refine methods that can significantly reduce the time required for analytic tasks in later program phases.\nCollectively, these robust interaction capabilities will help ensure that our knowledge graph remains a living, up-to-date resource that can rapidly evolve with analyst input and operational needs while minimizing analyst interaction overhead and cognitive burden.\nTask 4.2 | Enable real-time completion and gap detection The information captured within a knowledge graph, whether extracted from media sources or input by analysts, may not always encompass all logical relationships or conclusions that can be derived from the available data.\nIn such cases, additional nodes and edges may be inferred to enhance the graph\u2019s semantics and to provide higher level conclusions derived from the data which may be useful to analysts.\nTo address this, we will apply our method for inferring new logical connections for automated knowledge graph completion.\nThis method will derive new conclusions based on reasoning over the existing graph which are then introduced as new nodes or relationships.\nThese updates will be triggered whenever new information is input into the graph or when users make modifications which will ensure that the knowledge graph evolves dynamically and intelligently in response to user input.\nOnce new information is derived and integrated into the graph, we will perform logical consistency checks as outlined earlier.\nThis process will help ensure that the newly introduced relationships maintain the semantic and logical integrity of the entire knowledge structure and prevent contradictions or inconsistencies from arising.\nOn a technical level, our approach leverages our existing model capable of generating logical entailments from a set of multimodal knowledge.\nOur system will accept a claim graph alongside a target entailment label (e.g., entailment, contradiction, or neutrality).\nFor Phase 1, we will retrofit our fine- grained generation module to support knowledge graph completion.\nSpecifically, once a graph is constructed or edited by a user, we will aggregate relevant parts of the graph and feed them into our generation module.\nThe module, trained with a logical entailment critic, will then infer logically entailed relationships that are not yet present in the graph.\nThese new semantic conclusions, derived from existing evidence, will be automatically integrated into the graph as additional nodes or edges.\nAfter these updates, our consistency checking mechanism will be applied to verify the validity of the new conclusions, ensuring that they do not introduce contradictions or undermine the coherence of the graph.\nIn Phase I, we will focus on retrofitting our existing generator specifically for knowledge graph completion to measure the current abilities of the system to derive and integrate logically consistent relationships and conclusions into the knowledge graph.\nAdditionally, we will extend these capabilities to address information gaps within the graph.\nSpecifically, we will explore multiple methods to detect where the knowledge graph lacks sufficient evidential support.\nOne approach will involve prompting our generation module to produce neutral logical evidence with respect to the graph.\nPortions of the graph for which the model predicts \"neutral\" entailments\u2014where no strong logical support or contradiction is available\u2014will be flagged as potential Page 13 of 34",
        "21": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 information gaps.\nThese regions suggest that the graph lacks sufficient evidence for certain topics or relationships, and they will be highlighted for further review by analysts.\nThis feature will help analysts identify where more data collection or refinement is necessary which will help improve both the completeness and reliability of the knowledge graph.\nTask 4.4.\n| Enable conflict identification To ensure the knowledge graph remains coherent and reliable as users interact with and modify it, we propose to perform fine-grained logical entailment during interaction to check for introduced inconsistencies.\nWhile existing knowledge graphs often include relations such as co-reference, causal links, and hierarchical structures, they typically lack the logical relations that capture how individual facts combine to entail or contradict other facts.\nThis gap limits the graph's ability to support advanced reasoning and maintain consistency, especially when new information is added or existing information is altered.\nOur fine-grained logical entailment system will support fine-grained consistency checking of a claim knowledge graph.\nWe will apply this technique in Phase 1 to detect logical inconsistencies introduced as a result of edits or from conflicting knowledge sources.\nAs shown in Figure 9, we will extend our fine-grained multimodal logical entailment mechanism (Tang et al., 2024) to operate internally within the knowledge graph.\nOur technique will allow the system to infer logical implications and detect contradictions resulting from user modifications.\nSpecifically, when a user updates the graph\u2014by adding, deleting, or modifying nodes and edges\u2014we will identify relevant nodes not only through direct connections but also using retrieval techniques that operate over the entire graph's structure.\nOur entailment mechanism will then assess these nodes to determine logical relationships such as entailment, contradiction, or neutrality.\nThis approach goes beyond simple surface-level checks or propagating changes through co- referential edges.\nFigure 9 - Logical inconsistency and conflict identification Traditional methods might only flag direct inconsistencies, like conflicting attributes of a single entity.\nIn contrast, our technique will uncover deeper logical inconsistencies that may not be immediately apparent.\nBy considering how new and existing pieces of information logically combine, our proposed system will detect contradictions that emerge from indirect relationships or inferred knowledge.\nFurther, our extensions allowing for the addition of user-specified domain knowledge (using PyReason) will allow rapid identification and localization of inconsistencies among such knowledge, the elements of the graph, and other algorithmic-induced changes (Figure 10).\nFor example, in our recent work (Bavikadi, Lee, et al., 2024) we were able to provide human-understandable explanation as to why our PyReason-based Page 14 of 34",
        "22": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 systems produced likely future locations of suspicious maritime vessels.\nFigure 10 - PyReason framework supporting inconsistency checks Consider a scenario within the knowledge graph involving multimodal data: Fact A (Text Data): \"Agent Smith participated in a covert operation in Tokyo on September 12th, 2024.\" Fact B (Image Data): A photograph tagged with metadata indicating it was taken in Rio de Janeiro on September 12th, 2024, showing Agent Smith attending a diplomatic event.\nFact C (Existing Knowledge): \"There are no direct flights between Tokyo and Rio de Janeiro that take less than 24 hours.\" Each fact resides in a different modality and seems plausible individually.\nMoreover, no direct conflict arises from any of these facts.\nHowever, inferentially one can easily see that from Fact C, it's impossible for Agent Smith to travel from Tokyo to Rio de Janeiro within a 24-hour period resulting in a contradiction.\nThese types of fine-grained, semantically driven inconsistency judgments are not supported by current knowledge graph techniques.\nFor Phase 1, to achieve this level of sophisticated inconsistency detection, our system will extend the existing claim-based entailment mechanisms to operate across the entire knowledge graph.\nWe will use our entailment mechanism to evaluate how the new information interacts with existing data, inferring potential logical relationships (See Figure 11).\nOur system will highlight the detected logical inconsistency for the analyst\u2019s attention, providing contextual information such as the conflicting facts and the impossibility of rapid travel between the two locations.\nBy identifying these inconsistencies, the system can suggest additional possible changes to the graph based on the analysts\u2019 input.\nOur method will help ensure that as users interact with the graph\u2014making necessary changes to reflect new intelligence or correct AI/ML outputs\u2014the knowledge structure maintains a high level of consistency and trustworthiness.\nOur goal is to ensure that analysts can rely on the graph to provide accurate and logically coherent information.\nMoreover, this logical consistency checking reduces the cognitive load on analysts by automating the detection of inconsistencies that might otherwise require extensive manual review.\nIt allows them to focus on higher-level analysis rather than verifying the basic accuracy of the data.\nThis capability is particularly valuable in operational settings where information is rapidly evolving, and decisions must be made quickly based on the most accurate and coherent data available.\nPage 15 of 34",
        "23": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 Figure 11 \u2013 Generating fine-grained relationships in knowledge graphs.\nTask 4.4 | Enable graph schema updating A key aspect of maintaining an effective and adaptable knowledge graph is ensuring that its underlying schema evolves as new data and user modifications are integrated.\nIn this proposal, we will implement several schema updating mechanisms to ensure that the knowledge graph\u2019s ontology remains coherent and optimized for the evolving data structure.\nTo achieve this, we propose two complementary approaches that leverage state-of-the-art schema induction techniques (Jin et al., 2022; Zhang et al., 2023; Du et al., 2022; Hao et al., 2023), each designed to automatically refine and adapt the schema based on user edits and new data.\nZero-Shot Schema Induction for Dynamic Schema Updating When users make edits to the knowledge graph, we will trigger an automated schema update process.\nSpecifically, our system will leverage zero-shot schema induction techniques (Dror et al., 2023; Zhang et al., 2023; Li et al., 2023) on the edited portions of the graph.\nZero-shot schema induction allows us to generate new schema representations without requiring pre-labeled data to adapt the ontology to reflect the new terms used in the edits or modified knowledge.\nOnce the zero-shot schema is induced, we will perform schema matching between the newly induced schema and the existing knowledge graph structure.\nThis process ensures that any modifications introduced by the user are reflected in the most accurate and semantically aligned schema possible.\nIf the newly induced schema provides a better structural fit to the knowledge graph, as determined by semantic similarity metrics and schema matching algorithms (Wang et al., 2022), the system will automatically replace the existing graph schema with the refined version.\nProbabilistic Schema Induction and Divergence-Based Schema Refinement In parallel, we will implement a probabilistic schema induction technique that generates schema representations based on the statistical analysis of a set of documents or existing intelligence-based knowledge graphs.\nThis probabilistic approach generates schema with derived probabilities, reflecting how likely a particular schema structure represents the underlying data.\nAs users interact with the graph and make edits, we will continuously monitor how the edited graph aligns with the originally induced schema.\nTo ensure that the graph's structure remains semantically valid, we will perform lifelong schema matching by matching the edited graph with the induced probabilistic schema.\nIf the probability of the current graph's alignment with the original schema falls below a predefined threshold, indicating significant divergence from the original schema, the system will automatically re-initiate the schema Page 16 of 34",
        "24": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 induction process.\nDepending on the size and complexity of the graph, the system will either employ zero- shot schema induction for smaller graphs or probabilistic schema induction for larger, more complex graphs or those with enough data to meaningfully derive a probabilistic schema.\nThese techniques will allow the graph\u2019s schema to evolve in response to knowledge graph interaction without direct user intervention.\nTask 4.5.\n| Sensitivity Analysis to Direct User Attention One major challenge for human-machine interaction in knowledge graph development and refinement is identifying the aspects of the model most in need of human inspection or expertise.\nManually browsing a large knowledge graph to search for areas that might be improved, edited, or updated is intractable for human analysts and a poor use of their time and expertise.\nIn IKOS, we will develop a sensitivity and decision analysis microservice that will use proven, quantitative techniques to direct user attention to aspects of the model that would most benefit from refinement.\nSensitivity analysis and decision analysis techniques are often used to identify the most \u201cimportant\u201d features of a model and highlight the impact of variables or the stability of outcomes in a complex system.\nWhen used with decision support tools, sensitivity analysis provides a mathematically rigorous approach to model introspection and explanation, increasing transparency, enhancing interpretability, and increasing awareness of the model behavior (Guidotti et al.\n2018, Saltelli 2019).\nApplying sensitivity analysis techniques, especially to a complex graphical model, enables (1) increased awareness of model behavior; (2) understanding of model limitations; (3) understanding of areas requiring additional modeling efforts; (4) redirection of data collection to more important or impactful features; (5) proper communication of results; and (6) proper assessment of outcomes and effects.\nWe propose to adapt these tools to RESIN to help direct user attention to aspects of the model that might need updating or enhancement via human expertise or human-directed data collection.\nTable 1 describes the sensitivity analysis techniques that we will incorporate in IKOS.\nTable 1 - Sensitivity Analysis Techniques for IKOS Technique Factor-prioritization Trend determination Purpose \u2022 \u2022 \u2022 determine which features drive the results of a model prediction, and whether it is worth it to collect further data identify factors that may cause the predicted outcomes or optimal COA to change determine whether the model responds positively or negatively to input variations and can enable comparison of model results under different starting conditions \u2022 model debugging (e.g., is the response coherent with intuition?\nIs there incorrect or missing information?) \u2022 managerial action (if a variable has a positive impact, action must be taken \u2022 \u2022 \u2022 \u2022 \u2022 to guarantee the variable does not decrease) policy implementation determine whether two or more variables produce synergistic or antagonistic effects determine whether outcome is stable if inputs vary determine if a preferred strategy or observed effect is robust to variations in external factors assess frequency with which each COA or outcome is selected as optimal through objective optimization analysis Understanding interactions Understanding stability Frequency analysis Page 17 of 34",
        "25": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 Expected Value of Perfect Information Generalized Tornado Analysis \u2022 \u2022 quantify the degree to which the model results may be improved by gathering additional targeted data on specific variables or parameters assess the interaction effects of combinations of model variables and identifying which ones may jointly require attention to ensure model effectiveness Figure 12 illustrates the output of a Generalized Tornado Analysis on a knowledge graph representing the socioeconomics of agricultural production in Gambella, Ethiopia.\nThis analysis indicates for each node in the graph the individual effects of the variable (i.e., how \u201cinfluential\u201d is this variable in terms of the changes observed in predictive outcomes or optimal courses of action due to changes in the variable value), the interaction effects (i.e., how influential is this variable in concert with other variables), and the total effects.\nThe graph is sorted by total effect, with the most influential variables at the top.\nSuch analysis can help direct users to key aspects of the model to provide expertise and refinement.\nFor example, if the variables identified as most/least influential do not comport with the expert knowledge of the human analyst, then this indicates a case for perhaps updating and modifying model parameters.\nAlternatively, highly influential variables may indicate places where it is more critical to have accurate and sufficient data, indicating new data collection efforts may be needed.\nFigure 12 \u2013 Example Output of Generalized Tornado Analysis In the IKOS Phase I, we will develop prototype implementations of sensitivity analysis techniques to assess the feasibility of applying these techniques to knowledge graphs in the RESIN framework to identify key aspects for human expert attention.\nTask 4.6.\n| Translating Human Expertise into Probabilistic Model Parameters Knowledge graphs can provide representational richness in terms of relationships between entities and events, but for these frameworks to achieve their potential as decision support tools, they must also be computational, that is they must be able to perform some inference to answer key questions that may be posed by analysts.\nSuch questions may be in the form of hypothetical \u201cwhat if?\u201d scenarios to determine likely outcomes, identifying the optimal course of action (COA) for a real or hypothetical Page 18 of 34",
        "26": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 scenario, or identifying factors most influential in achieving a desired outcome.\nA wide variety of modeling frameworks exist to add computational capabilities into graphical knowledge representations to address the issues of stochasic relationships and influences\u2014probabilistic graphical models (e.g., Bayesian networks (Pearl, 1988), influence diagrams (Howard and Matheson, 2005), probabilistic relational models, (Getoor, et al., 2007)), probabilistic soft logic (Kimming et al., 2012), Markov logic networks (Richardson and Domingos, 2006), and many others.\nHowever, humans, regardless of the depth of their domain expertise, are notoriously bad at estimating probabilities, and even worse at estimating the complex probabilistic relationships and interactions required by these computational modeling frameworks.\nTo address this issue, we propose adapting an approach originally developed for timed influence nets (TIN) (Haider and Levis, 2008) a probabilistic graphical model that is a variation on a standard influence diagram (Howard and Matheson, 2005) that captures probabilistic and uncertain influences in dynamic environments.\nTINs were originally developed for use in intelligence analysis as a means of providing analysts with an intuitive knowledge representation that could also be used computationally for prediction and inference.\nLike classic influence diagrams, a TIN contains different types of nodes\u2014those that represent random variables and those that represent decisions\u2013and can be trans- formed to a Bayesian network (Pearl, 1988) for analysis and inference.\nHowever, in TINs, the model parameters (i.e., the influence parameters) are described in the Causal Strength (CAST) (Haider & Levis, 2008) format indicating the conditional influence of the parent nodes on their children.\n(An example TIN is shown in Figure 13.) The CAST representation was originally developed for TINs to provide domain experts with a more intuitive method for specifying probabilistic influence relationships, requiring fewer parameters than standard Bayesian conditional probability tables (CPTs).\nIn CAST: \u2022 A base probability is specified for each node, indicating the independent, unconditional \u2022 likelihood of an event.\nEach edge contains two influence values indicating the strength of the influence when the parent is true or false \u2022 Using these values, the CAST algorithm computes the remaining CPT parameters, enabling the TIN to be interpreted as a fully specified Bayesian network or influence diagram.\nFigure 13 \u2013 Timed Influence Network (TIN) of the agroeconomic dynamics in Gambella, Ethiopia.\nBase probabilities are specified by food security experts.\nUsing this intuitive TIN framework, it is possible for users to modify not only the schema and relationships in a complex knowledge graph, but also apply their expertise to the initialization or tuning of Page 19 of 34",
        "27": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 quantitative parameters that enable using the knowledge graph as a computational model for purposes of predictive or explanatory analytics.\nThe output of the TIN will work as part of our overall strategy for augmenting graphical information with expert domain knowledge using PyReason.\nIn short, we can use a TIN to provide an output of a posterior probability that can be then directly represented in PyReason and used in downstream inference tasks on RESIN.\nFurther, the ability to identify inconsistencies of such knowledge with the graphical constructs in the resin system can allow feedback to the user to adjust causal strength parameters when attempting to rectify inconsistencies In Phase I, we will demonstrate the feasibility of representing a knowledge graph computationally as a TIN and leveraging the output for downstream analytic modeling tasks using PyReason and the RESIN system.\nTask 5 | Project Management BRG\u2019s agile project management approach will be used to organize the division of labor, monitor, and manage technical implementation tasks, and set clear timelines and benchmarks for IKOS.\nThe IKOS team will employ proven methods for distributed work and agile software development.\nThe PI and PM are former military officers with over 20 years\u2019 experience with planning and directing team projects.\nThe key persons on IKOS have extensive experience leading research and technology programs.\nThe project manager has a PMP certification and has experience with managing agile software development projects.\nThe PI or PM will organize weekly team meetings via Zoom or Microsoft Teams in addition to the bi- monthly meetings with the Sponsors.\nDocuments, tasking, data, and code will be shared through Teams and Git.\nThe deliverables from this task include monthly financial reports and progress reports as described in paragraph d below.\nc.\nMilestone Schedule The Schedule for the proposed project is shown below in Table 2.\nTable 2 - Project or Milestone Schedule Tasks M1 M2 M3 M4 M5 M6 Objectives 1: Mission Engineering X X X X X X 2: Data Acquisition 3: Generate Initial Knowledge Graph 4: Develop Interactive Knowledge Graph Features X X X X X X X X X \u2022 User and workflow models \u2022 Use cases \u2022 Performance measures \u2022 Transition/Commercialization Plan \u2022 Access to ION data \u2022 Initial multi-modal KG for use by OSINT analysts \u2022 Feasibility assessment of our approaches to allow inspecting, editing, sharing, and consistency checking of KGs 5: Project Management X X X X X X \u2022 Project reports and Phase 2 proposal plan d.\nDeliverables We will schedule a kickoff briefing within 30 days after contract award to review project objectives, activities, and milestones and discuss feedback with the Sponsor.\nThe deliverable for this effort will be a final report of background, anticipated functionality, technical challenges for software development and implementation, and recommendations for prototype development.\nPage 20 of 34",
        "28": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 Deliverable Refined execution plan Progress Reports Final Report with SF 298 4.\nRelated Work Date Kickoff meeting Month 2, 4 Month 6 Founded in 2020, BRG is a human-machine systems company, specializing in designing, planning, and developing trustworthy, fieldable systems for high-risk domains and high-performance organizations.\nBRG comprises experts from across military operations, engineering, data science, and cybersecurity domains who understand the \u201cFull Capability Stack\u201d, which integrates hardware, software, and people as a cognitive work system.\nThe team proposed for this project brings extensive individual experience.\nSpecific related projects of key persons on this project are shown Table 3.\nTable 3 - Past related projects Project Name Sponsor TechSuite Contract FA8649-19-9- 9038 POC J.\nGraley PoP Aug \u2013 Oct 2020 Description Developing a cloud compute environment to enable AI in support of SBIR proposals, subcontract to Mile Two.\nUSAF SBIR/STTR Office (Subk to Mile 2) AFRL (Subk to Mile 2) RAINFLY (Phase 1) E.\nThompson Oct 2023 \u2013 Sep 2024 Employ Mission Engineering to design a system to support Information Warfare through the application of human performance findings ReSCIND (Phase 1) IARPA (Subk to Raytheon) K.\nFerguson- Walter Jan 2024 \u2013 July 2025 GSA 47QFLA23D0001/ TO 47QFLA23F0061 N66001-24-C- 4504 SemaFor DARPA HR001120C0123 W.\nCorvey July 2020 \u2013 Jan 2025 AIDA DARPA FA8750-18-2- 0014 B.\nOnyshkevych Jan 2018 \u2013 Jan 2023 KAIROS DARPA FA8750 19-2- 1004 B.\nOnyshkevych July 2019 \u2013 Dec 2023 Serve as Lead Systems Integrator to deliver a novel, containerized cybersecurity application.\nEmploy Mission Engineering to inform system design and development and testing experiments.\nExecute a campaign of human subjects experiments to provide data for model training and system testing.\nRepresented Columbia developing semantic defenses for detecting generated media.\nDeveloped a multimodal knowledge graph- based generated content detection system and components for fine-grained logical reasoning over multimedia.\nContributed to GAIA knowledge extraction system by developing methods for jointly extracting knowledge from videos and articles and extended system for downstream applications.\nContributed components for multimedia knowledge graph extraction, such as cross- modal event relation prediction, multimedia information extraction, and cross-modal temporal multimodal alignment for knowledge graph construction.\nAugmenting the PyReason framework to support ISR-reasoning task.\nMCAI DARPA Reasoning about Global Supply Networks ONR Cooperative agreement HR00112420370 N00014-23-1- 2580 N.\nBastian July 2024 \u2013 June 2025 D.\nPhillips May 2023 \u2013 May 2026 Augmenting PyReason for reasoning about supply networks and maritime vessel movement.\nThe IKOS Team has extensive experience using and extending RESIN multimodal knowledge graph extraction systems.\nDr.\nThomas has worked on several components that were integrated into the system.\nSpecifically, Dr.\nThomas has worked on enhancing the ability of RESIN systems to extract cross-modal event Page 21 of 34",
        "29": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 structures from video and news articles with limited supervision.\nTogether with fellow researchers, Dr.\nThomas created models which can jointly extract events from video and articles (Chen et al., 2021).\nThe model developed from this research was integrated into the RESIN system (Du et al., 2022).\nIn follow-up work, he developed enhanced video-text alignment models that rely on temporal constraints to achieve better alignment over the prior approach to enhance the ability of the system to learn the connections between modalities without strong supervision (Chen et al., 2022).\nDr.\nThomas has also worked as part of the DARPA KAIROS program on learning new types of cross- modal relationships to enhance knowledge graph\u2019s representations.\nDr.\nThomas and collaborators developed a multimodal relationship prediction model to detect indirect relationships between text and visual content, whereas prior systems only handled cases where the visual and textual content were directly aligned (Ayyubi et al., 2022).\nDr.\nThomas has also deployed the knowledge graph extraction systems described for downstream reasoning applications.\nDr.\nThomas and colleagues developed the InfoSurgeon fine-grained knowledge inconsistency detection system for detecting machine-generated multimedia news articles (Fung et al., 2021).\nThe system makes use of the RESIN knowledge graph extraction system to extract a multimodal knowledge graph from multimedia news articles.\nThen, the knowledge graph is instantiated in a graph neural network, and predictions are made for each relationship within the graph.\nNot only did the system outperform the state-of-the-art machine-generated detection system at the time substantially, but it was also capable of producing fine-grained explanations of its predictions by identifying the specific inconsistencies within the knowledge structure.\n5.\nRelationship with Future Research and Development a.\nAnticipated Results In Phase I, our primary objective is to demonstrate a proof-of-concept system that effectively supports user interaction with a dynamic multimodal knowledge graph.\nWe will leverage the existing RESIN framework, repurposing its components alongside more recent multimedia knowledge graph extraction techniques.\nThe process will begin with generating a base knowledge graph from multimedia sources, integrating a number of refinement techniques to enhance accuracy and completeness as well as better align with analyst domain knowledge.\nKey components as described above include knowledge graph completion, logical inconsistency detection, information gap detection, and schema matching and refinement.\nThese components will collectively contribute to refining the initial knowledge graph extracted by our system and will also refine the graph after interactions.\nTo establish a functional interactive interface, we plan to extend the existing RESIN Editor and our PyReason framework to facilitate direct user interaction with the knowledge graph.\nAnalysts will have the option to interact with the graph using both manual edits and natural language commands, which will be translated into a series of structured graph operations.\nAfter any user modifications, the system will reapply the refinement techniques to ensure semantic consistency and coherence across the updated knowledge graph.\nWhile we expect Phase I to deliver a foundational proof-of-concept for knowledge graph refinement, there will be notable limitations.\nFor instance, the proposed knowledge graph completion approach relies on fine- grained logical entailment generation to infer new relationships or entities based on existing evidence.\nA core challenge is determining the appropriate set of evidence to provide as input for this inference process.\nIn this phase, we will use a graph traversal technique to aggregate information within a limited radius of selected nodes, as outlined in Tang et al.\n(2024), or use our recent multimedia evidence summarization approach to retrieve relevant evidence (Chen et al.\n2024).\nHowever, both approaches have scalability challenges; as the knowledge graph expands, traversal becomes computationally intensive and dependent on the relevance of the selected evidence.\nInaccurate evidence selection can lead to erroneous inferences, potentially reducing the quality of knowledge graph completion.\nConsequently, in Phase I, we expect to achieve primarily shallow inferences, introducing straightforward relationships and new entities from localized multimedia data.\nThe synthesis of more complex inferences, particularly those requiring the integration of distantly related evidence, will almost certainly remain beyond the capabilities of the Phase I prototype.\nAs such, the proposed system\u2019s capacity for deeper, multimodal knowledge synthesis is anticipated to be limited and will be explored further in Phase II.\nOur approach for logical inconsistency and gap detection uses our fine-grained entailment classifier (Tang et al.\n2024) as well as the use of deductive inference via PyReason (Aditya et al., 2024) applied within the Page 22 of 34",
        "30": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 multimedia knowledge graph.\nUnlike the knowledge graph completion technique, which depends on the logical entailment generator, this component leverages a classifier to identify inconsistencies by evaluating the logical alignment between knowledge graph elements and supporting multimedia evidence.\nWe anticipate that this approach will effectively detect semantic inconsistencies when provided with relevant, semantically related evidence from the knowledge graph.\nHowever, like the challenges faced in knowledge graph completion, this technique requires identifying the correct set of supporting evidence for each knowledge element under review.\nDetermining the most relevant evidence for logical entailment is complex, as the logical relationships within the knowledge graph can be indirect or involve semantically distant facts.\nIn Phase I, we will detect and explain logical inconsistencies arising from analyst domain knowledge \u2013 which will provide evidence back the analyst on the source of the inconsistency.\nAdditionally, for classifier-based inconsistency (Tang et al., 2024), , we plan to utilize evidence retrieval techniques, incorporating graph traversal algorithms to select evidence within a specified distance from the target node.\nThis strategy will allow us to conduct fine-grained logical entailment verification when evidence is within reasonable semantic proximity to the hypothesis being tested.\nSimilarly, our gap detection approach will identify portions of the knowledge graph where entailment confidence is low or where the classifier predicts neutrality, indicating weak or insufficient evidence for nodes or relationships.\nThese nodes and edges will be flagged as areas with weaker evidential support, suggesting potential information gaps that may require further refinement or additional data integration.\nIn Phase I, we anticipate that gap detection will be feasible primarily for cases involving semantically related evidence, with more complex gap identification being deferred to Phase II.\nOur schema matching and refinement components will leverage the existing schema matching and schema induction techniques embedded within RESIN.\nAfter generating initial schemas, we will align the knowledge graph to one or more of these schemas, providing analysts with a high-level structural overview that aids in understanding the relationships within the graph.\nAs analysts interact with and refine the knowledge graph through our updated RESIN-Editor, we will initiate a new round of knowledge graph refinement, followed by another schema matching step.\nThis process will measure whether the schema continues to accurately represent the updated knowledge graph.\nIf the fit between the graph and the schema falls below a predefined threshold, the system will trigger schema induction to generate an updated schema.\nHowever, there are several limitations to this baseline approach.\nThe current design does not explicitly track user-made updates in the knowledge graph to inform the schema induction process.\nAs a result, it does not assign greater weight to user edits compared to pre-existing data which reduces the accuracy of induced schemas.\nIn Phase I, we anticipate that our system will match the multimodal knowledge graph to a set of schemas that can adapt to user edits.\nHowever, the refinement process will offer limited control over schema induction, with no direct user input for schema manipulation.\nIn addition, while the RESIN Editor's extensions will facilitate user interaction with the knowledge graph itself, they will not support direct manipulation of the schema.\nAny schema changes will occur indirectly, reflecting the user's modifications to the instance graph rather than allowing direct schema edits.\nIn future program phases, we plan to introduce more advanced schema controls that enable finer adjustments to both the schema induction and matching processes, allowing for improved alignment with operational use cases as required by analysts.\nLastly, our multimedia knowledge graph extraction and refinement components rely on static vision and language models, which will not be updated through user interaction.\nWhile we expect this initial design to function reasonably as a proof-of-concept in Phase I, it overlooks a potentially useful supervisory signal inherent in the user edits to the knowledge graph.\nAs user modifications are not used to refine the underlying models, there is a potential risk of user frustration, as they may need to repeatedly correct similar errors in different operational contexts.\nFor example, if the system consistently fails to extract a specific type of multimodal information, users will have to insert this data repeatedly manually or correct the same error repeatedly across various use cases, leading to increased cognitive load and reduced operational efficiency.\nIdeally, all components of IKOS\u2014including knowledge graph extraction, vision feature detection, and refinement modules\u2014would dynamically adapt in response to user edits, ensuring that user feedback informs and improves the system\u2019s performance.\nIn Phase II, we plan to address this gap by leveraging user interactions as an additional supervisory signal.\nThis will enable adaptive refinement of all components Page 23 of 34",
        "31": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 involved in knowledge graph extraction and refinement which will ultimately improve the system's responsiveness and reduce the need for repeated corrections of the same issues by analysts.\nb.\nSignificance of Phase 1 as foundation for Phase 2 In Phase 1, we will develop a prototype of the IKOS system capable of extracting a multimedia knowledge graph, performing basic refinement, and enabling user interaction.\nWhile this initial version will have limitations, as outlined in the anticipated results section, it will serve as a critical foundation for Phase 2.\nThe Phase 1 prototype will expose us to several crucial challenges inherent in applying the RESIN framework to intelligence analysis use cases, offering valuable insights that will inform larger-scale development efforts in Phase 2.\nThis initial system will act as a testbed, allowing us to evaluate both the strengths and shortcomings of the existing RESIN extraction capabilities and the newer components we integrate.\nIn particular, Phase 1 will provide a clear understanding of how well our knowledge completion, inconsistency detection, and schema refinement modules perform in real-world intelligence scenarios.\nFor knowledge completion specifically, we aim to study the types of missing information introduced by users and the extent to which this missing knowledge could have been automatically inferred by the system.\nThis will help motivate the need, if it exists, for automatically refining IKOS\u2019 multimodal information extraction capabilities on the fly.\nFurther, by tracking the provenance of user-added knowledge, we will gain insights into the degree of indirect knowledge relationships required for effective completion.\nThe extent of such indirect, complex multimodal knowledge synthesis remains uncertain in operational intelligence settings, making the Phase 1 system a valuable testbed to explore these dynamics.\nAdditionally, our approach for logical inconsistency and gap detection will help identify the extent to which the system can detect semantic inconsistencies requiring multi-hop and multi-modal inferences as well as inconsistencies with analyst-specified domain knowledge.\nWe will explore the limitations of the current system, particularly its ability to handle complex inconsistencies that involve intermediate conclusions across different modalities.\nThis includes determining whether more sophisticated evidence retrieval techniques, beyond surface-level semantic similarity, are needed to identify logically relevant evidence.\nWe will also evaluate the effectiveness of gap detection in identifying evidential gaps or perspective gaps that could have operational significance, such as missing evidence that might support or refute critical hypotheses.\nBy leveraging the RESIN system\u2019s disparate hypothesis generation capabilities, we will test the system\u2019s potential to propose missing hypotheses of interest.\nThis exploration will help us understand the technical limitations of our current gap detection capabilities, which can then be refined in Phase 2 to better address analyst requirements and reduce cognitive burden.\nLastly, for schema induction and refinement, Phase 1 will explore how well customized schemas can align with operational intelligence workflows.\nWe will investigate the degree to which schemas generated in Phase 1 support specific analytical tasks and how effectively these schemas can be adapted to different intelligence analyst use cases.\nOur results from this phase will directly inform the development of more advanced schema induction techniques in Phase 2, such as dynamic schema customization based on completed workflows, user queries, and analyst feedback during interactions.\nBy analyzing various use cases, we will assess the feasibility of task-driven schema adaptation and the potential for schema learning from past interactions or training data.\nThese insights will shape Phase 2's design to ensure that the knowledge graph system can better meet diverse operational demands.\nc.\nRequirements for Phase 2 IKOS is envisioned to delivery software that can be integrated into a government program of record that supports intelligence analysis.\nAccordingly, IKOS will require an architecture and system security plan that will support such integration.\nThe lead security engineer for BRG has experience with managing the Risk Management Framework to achieve an Authority to Operate on other classified information systems.\nAs described in our Statement of Work above, our mission engineering efforts will connect us with at least one applicable program office (i.e., C2IE), and orient our design to meet their system architecture requirements.\nTo execute our proposed mission engineering effort, some of our team will require TS security clearances.\nThis will allow us to visit and interact with contemporary OSINT analysts and transition program Page 24 of 34",
        "32": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 officers.\nBRG has a TS facility clearance, and key persons on this project have active TS-SCI clearances.\nWe will request a DD-254 for this project to support the clearances necessary for our proposed work.\n6.\nCommercialization Strategy a.\nFirst Targeted Product The initial focus for IKOS is to deliver capabilities to military intelligence programs of record, beginning with the Command and Control of the Information Environment (C2IE), an analytic platform that provides open-source data as a means of real-time situational awareness.\nIKOS\u2019s multimodal data integration will strengthen C2IE\u2019s capacity to deliver actionable intelligence.\nIn the private sector, IKOS will be positioned as a business intelligence (BI) solution for critical infrastructure firms (e.g., energy providers, financial firms), where real-time insights drive essential decision-making (U.S.\nDepartment of Homeland Security, 2024).\nb.\nCustomers and estimated market size.\nThe DoD has allocated $1.4 billion in 2024 for information dominance and is likely to increase these investments in future years as it postures for conflicts in the Pacific (U.S.\nDepartment of Defense, 2023).\nAccordingly, DoD programs such as C2IE represent significant customers for IKOS.\nIn the private sector, IKOS will offer great value to companies seeking intelligence to protect critical infrastructure.\nCurrent business intelligence platforms fail to meet the decision support demands for these companies.\nAs shown in figure 14, the global business intelligence market in 2024 is estimated at $21.1 billion, with a CAGR of 10.8% through 2033 (Persistence Market Research, 2023).\nWithin this landscape, knowledge graphs offer an unmet need for a $1.1 billion segment that has a 21.8% CAGR (Markets & Markets, 2024).\nIKOS will foreseeably provide value to the 10,000 U.S.\ncritical infrastructure entities, which represent a total $500 million opportunity based on average implementation costs for open-source intelligence.\nFigure 14 - IKOS target market size c.\nFunding required to bring the technology to market and how will that money be raised Beyond the research and development funding from Phase 2 SBIR award, we will seek additional venture capital to bring IKOS to market.\nAs we near completion of Phase 2, we plan to seek $3 million in venture capital for a Series A investment.\nThis funding will allow us to decide whether to license the capability to existing platforms or seek additional funding (Series B) to bring a new platform to market.\nWe anticipate Series B funding to be approximately $10 million for our $500 million market valuation described above.\nTo raise these investments, BRG will leverage its established networks of investment bankers.\nIn particular, we will target venture capital firms known for successfully scaling and exiting positions in business intelligence platforms, such as Baird Capital, Viking Global Investors, and Grotech Ventures.\nSuch partnerships will enable strong market penetration and create additional value for users of IKOS.\nd.\nCorporate marketing expertise or plan to bring that into the company BRG\u2019s current marketing strengths are in the defense and cybersecurity sectors.\nWe will bring business intelligence marketing expertise on board with Series A investment.\nThis will initially be contracted marketing from established firms specializing in marketing novel innovative solutions.\nOur preferred advertising firm is Robot House.\nRobot House offers boutique advertising out of Oklahoma City, and benefits from its proximity to critical infrastructure providers in the energy sector.\ne.\nCompetitors and BRG Competitive Advantage over the competitors Competing intelligence platforms, such as the commercially available AlphaSense and Tellius, incorporate knowledge graphs as ancillary features, yet lack the specialized configurations essential to drive informed Page 25 of 34",
        "33": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 decisions in government and critical infrastructure (Owler, 2024).\nBRG distinguishes itself from these platform providers with its focus on mission engineering and advanced technology development.\nf.\nSchedule Table 4 provides a high-level description of our phased commercialization approach for IKOS.\nTable 4 - Commercialization Schedule Phase I.\nConcept and Feasibility Duration 6 months \u2022 Objectives Establishing feasibility and aligning with market needs; refining commercialization strategy 12 months \u2022 Refining product and testing in real-world settings; preparing II.\nResearch and Development III.\nCommercialization 24 months venture capital pitch Transition roadmap with DoD program of record Transition IKOS to a DoD program of record Series A ($3M) fund raise \u2013 year 3 Series B ($10M) fund raise \u2013 year 4 \u2022 \u2022 \u2022 \u2022 7.\nKey Personnel BRG is a non-traditional defense contractor that only employs U.S.\nCitizens.\nAdditionally, no subcontractors or consultants will be employed in the proposed work.\nSpecific publications for key persons are included in bold in the references section.\nStoney Trent \u2013 Principal Investigator Education: University of Notre Dame, B.S.\n\u2013 Mechanical Engineering, 1995 The Ohio State University, M.S.\nSystems Engineering, 2005 The Ohio State University, Ph.D.\nSystems Engineering, 2005 Relevant Experience: Cognitive Engineer and Military Intelligence and Cyber Warfare veteran with over 15 years of experience leading mission engineering for the defense and intelligence communities.\nDr.\nTrent is the President of BRG and a research professor at the Virginia Tech National Security Institute, where he focuses on human-machine teaming and trustworthy AI systems.\nWhile on active duty, he designed the Joint Artificial Intelligence Center (JAIC) for the Department of Defense, where he established product lines to deliver human-centered AI to improve warfighting and business functions.\nDr.\nTrent is a co-PI on IARPA ReSCIND, where he is leading mission engineering, experimentation, and system integration for a project to deliver AI-enabled cybersecurity capabilities.\nDr.\nTrent is also a PI on AFRL RAINFLY, where he is leading the design and system integration for a cognitive psychology- based Information Warfare capability.\nDr.\nTrent is a graduate of the Army War College and former Cyber Fellow at the National Security Agency.\nRelevant Awards / Patents: Defense Superior Service Medal \u2013 Establishing mission engineering methods that contributed to the successful delivery of AI-enabled capabilities at the Joint AI Center Relevant Publications: Trent, S., Patterson, E., Woods, D.\n(2007).\nChallenges for cognition in intelligence analysis.\nJournal for Cognitive Engineering and Decision making.\nChris Thomas \u2013 Lead Computer Scientist (co-PI) Education: University of Pittsburgh, B.S.\n- Computer Science, 2013 University of Pittsburgh, PhD - Computer Science, 2013 Postdoctoral Researcher, Columbia University, 2020-2022 Relevant Experience: Page 26 of 34",
        "34": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 Chris Thomas, Ph.D., is an Assistant Professor in the Department of Computer Science at Virginia Tech.\nHis research interests lie at the intersection of computer vision and natural language processing.\nA primary focus of his research is to build robust AI systems that can understand and reason about real-world multimedia content (images, text, video, and audio) as humans do.\nHe previously represented Columbia University in the DAPRA SemaFor program focused on disinformation detection.\nHe has also worked as part of other DARPA programs focused on multimedia understanding and knowledge graphs including AIDA and KAIROS.\nHis work has appeared in top conferences and journals, including CVPR, ACL, NeurIPS, ECCV, IEEE PAMI, and IJCV.\nHe has served on program committees for over twenty conferences and journals and has won six outstanding reviewer awards at top vision conferences (CVPR, ICCV, ECCV).\nHe has diverse ongoing interdisciplinary collaborations with faculty from other fields and institutions, including Columbia, UIUC, UCLA, and the University of Pennsylvania.\nRelevant Publications: Tang, C.-W., Chen, T.-C., Ishmam, A.\nM., Nguyen, K.\nA., Mehrab, K.\nS., & Thomas, C.\n(2024).\nM3D: MultiModal MultiDocument Fine-Grained Inconsistency Detection.\nTo appear, In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing.\nLong papers.\nThomas, C., Zhang, Y., & Chang, S.\nF.\n(2022, October).\nFine-grained visual entailment.\nIn European Conference on Computer Vision (pp.\n398-416).\nCham: Springer Nature Switzerland.\nFung, Y., Thomas, C., Reddy, R.\nG., Polisetty, S., Ji, H., Chang, S.\nF., ...\n& Sil, A.\n(2021, August).\nInfosurgeon: Cross- media fine-grained information consistency checking for fake news detection.\nIn Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) (pp.\n1683-1698).\nChen, T.\nC., Tang, C.\nW., & Thomas, C.\n(2024, August).\nMetaSumPerceiver: Multimodal Multi-Document Evidence Summarization for Fact-Checking.\nIn Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp.\n8742-8757).\nAyyubi, H., Thomas, C., Chum, L., Lokesh, R., Chen, L., Niu, Y., ...\n& Chang, S.\nF.\n(2024, March).\nBeyond Grounding: Extracting Fine-Grained Event Hierarchies across Modalities.\nIn Proceedings of the AAAI Conference on Artificial Intelligence (Vol.\n38, No.\n16, pp.\n17664-17672).\nChen, L., Niu, Y., Chen, B., Lin, X., Han, G., Thomas, C., ...\n& Chang, S.\nF.\n(2022).\nWeakly-Supervised Temporal Article Grounding.\nIn 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022.\nChen, B., Lin, X., Thomas, C., Li, M., Yoshida, S., Chum, L., ...\n& Chang, S.\nF.\n(2021, November).\nJoint Multimedia Event Extraction from Video and Article.\nIn Findings of the Association for Computational Linguistics: EMNLP 2021 (pp.\n74-88).\nPaulo Shakarian \u2013 Senior Computer Scientist Education: United States Military Academy, B.S.\n- Computer Science, 2002 University of Maryland, College Park, M.S.\n\u2013 Computer science, 2009 University of Maryland, College Park, Ph.D.\n\u2013 Computer science, 2011 Relevant Experience: A Senior Computer Scientist at BRG and a tenured Associate Professor in the School of Computing and AI at the Fulton Schools of Engineering at Arizona State University.\nHe also holds the additional position as Research Director for the School of Computing and AI at ASU.\nHe specializes in the fusion of symbolic artificial intelligence and machine learning \u2013 publishing numerous scientific books and papers.\nShakarian was named a \u201cKDD Rising Star,\u201d received the Air Force Young Investigator award, received multiple \u201cbest paper\u201d awards and has been featured in major news media outlets such as CNN and The Economist.\nPaulo has been funded by various organizations including IARPA (HAYSTAC, CAUSE, ICARUS), ARO (4x), ONR (5x), AF/AFOSR (2x), and DARPA as well as various industry partners.\nPaulo also co-founded a startup company that used machine learning to predict future exploits; the company was acquired after raising $8 million in venture capital and having obtained over 80 customers.\nPaulo also founded and manages the Neuro Symbolic Channel on YouTube which has over 2,500 subscribers.\nEarlier in his career, Paulo was an officer in the U.S.\nArmy where he served two combat tours in Iraq, earning a Bronze Star and the Army Commendation Medal for Valor.\nDuring his military career, Paulo also served as a DARPA Fellow and as an advisor to IARPA.\nRelevant Awards / Patents: Page 27 of 34",
        "35": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 Holds 10 issued US patents, prior experience commercializing AI technology used by cybersecurity analysts, prior training as an intelligence anlyst (Army Military Intelligce Officer Basic and Captain Career course graduate) Relevant Publications: D.\nBavikadi, D.\nAditya, D.\nParkar, P.\nShakarian, G.\nMueller, C.\nParvis, G.\nSimari, Geospatial Trajectory Generation via Efficient Abduction: Deployment for Independent Testing, 40th Intl.\nConference on Logic Programming (ICLP-24).\nD.\nAditya, K.\nMukherji, S.\nBalasubramanian, A.\nChaudhary, P.\nShakarian, PyReason: Software for Open World Temporal Logic, AAAI Spring Symposium (Mar.\n2023).\nAmy Sliva \u2013 Senior Computer Scientist Education: Georgetown University, B.S.\n- Computer Science, 2005 University of Maryland, College Park, M.S.\n\u2013 Computer Science, 2007 University of Maryland, College Park, M.P.P.\n\u2013 International Security and Economic Policy, 2010 University of Maryland, College Park, Ph.D.\n\u2013 Computer Science, 2011 Relevant Experience: A computational social scientist with expertise in artificial intelligence, cyber security, and international security and economics.\nAmy is an Assistant Professor and Program Director of Computer Science at King\u2019s College and has also served on the faculty of Northeastern University in both Computer Science and Political Science.\nShe has over 15 years\u2019 experience developing large-scale data analytics and artificial intelligence models of human behavior to support decision making in the National Security and Intelligence Communities.\nAs an experienced Principal Investigator and Project Manager for DARPA and IARPA Prime contracts and DoD SBIRs, Amy has led commercial and research software development to include the development and use of APIs.\nRelevant Awards / Patents: Text Relevant Publications: \u201cDecision Analysis in Stochastic Sociocultural Systems\u201d (with Emanuele Borgonovo, Alexander Levis, Christopher Pawlenok, and Nathaniel Plaspohl).\nProceedings of 27th International Conference on Analytical & Stochastic Modelling Techniques & Applications (ASMTA), 2023.\n\u201cCausal Analysis Graph Modeling for Strategic Decisions\u201d (with Alexander Levis).\nIn Proceedings of European Council for Modelling and Simulation (ECMS) 36th International Conference on Modelling and Simulation, 2022, \u201cFood Security in Developing Economies: A Decision Analysis Approach\u201d (with Alexander Levis, Emanuele Borgonovo, and Glenn Takata).\nInstitute for Operations Research and the Management Sciences (INFORMS) Annual Meeting.\n2020.\nBrandon Beltz \u2013 Senior User Experience Researcher Education: University of Utah, B.S.\nPhilosophy, 2000 George Mason University, M.A Experimental Psychology, 2004 George Mason University, Ph.D.\nExperimental Psychology, 2009 Relevant Experience: Brandon Beltz is a Principal User Experience Researcher at the Bulls Run Group with 16 years of experience enhancing software product usability and adoption.\nHe has led multimethod research projects across several industries including digital health, finance, and intelligence analysis tools.\nHis professional roles have included Senior User Research Manager at Sage, Director of User Experience Research at Vibrent Health, and user experience leadership roles at MITRE and Northrop Grumman.\nRelevant Awards / Patents: None Relevant Publications: None James Doty III \u2013 Project Manager and Intelligence Analysis SME Page 28 of 34",
        "36": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 Education: USMA, B.S.\nHistory, 1995 The Ohio State University, M.A.\nHistory, 2005 The Ohio State University, Ph.D.\nHistory, 2010 Relevant Experience: A Military Intelligence veteran, historian, and is the Chief of Project Management for the BRG.\nDr.\nDoty specializes in translating operational experiences for technology programs.\nHe has over 20 years\u2019 experience leading analytic teams and preparing assessments for senior leaders.\nAs the Senior Intelligence Officer for the National Training Center (NTC) in Fort Irwin, CA, Jim coordinated the planning and execution of intelligence training and wargames for Army units preparing to deploy and collaborated with the Defense Advanced Research Projects Agency\u2019s INSIGHT program.\nAs a Professor of Military Science, he directed leadership and military technical training for cadets preparing for commissions in the US Army.\nJim has served as a Strategic Policy Research Fellow with the RAND Arroyo Center and is a former Assistant Professor of Military History at the United States Military Academy.\nHe has deployed to combat and other operations in Iraq, Saudi Arabia, Germany, and Kosovo.\nDr.\nDoty will serve as the Project Manager and Intelligence SME.\nRelevant Awards / Patents: None Relevant Publications: None Van Truong \u2013 System Architect / Senior Software Engineer Education: NC A&T State University, M.S.\nin Computer Science, 2009 NC A&T State University, Computer Science, 2007 Relevant Experience: Senior Software Engineer with over 15 years of experience in defense and commercial projects involving software development, testing, and automation.\nHe has excelled in roles that include tester, developer, system administrator, and tech lead for the various systems, including radar systems, satellite systems, transportation systems, MES systems, and smart technical manuals.\nMr.\nTruong is currently the Lead System Integrator on IARPA ReSCIND, where he is integrating AI modules and other software components to deliver a containerized cybersecurity application.\nPreviously, Mr.\nTruong was in the Raytheon Rotation Leadership Development program, where he went through cross-functional training and leadership development.\nVan has Security+ and Raytheon Six Sigma certifications.\nVan has a bachelor's and master's degree in computer science with a master's thesis in natural language processing (NLP) for assisting semi-auto tutoring systems.\nHe will serve as the Lead Software Engineer.\nRelevant Awards / Patents: None Relevant Publications: Developing an Algebra Sublanguage for Tutorial Dialogues, Twentieth Midwest AI And Cognitive Science Conference (MAICS 2009), Fort Wayne 8.\nForeign Citizens.\nNone 9.\nFacilities/Equipment.\nBRG operates a distributed software factory with all team members using AWS GovCloud and Microsoft Government Cloud Compute High for development and storage of Controlled Unclassified Information.\nBRG is FEDRAMP and NIST compliant.\nAll workspaces meet local, state, and federal environmental and safety regulations.\nBRG will develop the objective system in accordance with ISO/IEEE 12207 Systems and software engineering software life cycle processes and CMMI best practices.\nUsing CI/CD and Agile development processes, BRG delivers rapid prototypes that are ready for rapid transition.\nIn general, our software teams employ two-week sprints consisting of planning, development, review, and feedback every month.\nAs a Cybersecurity Maturity Model Certification Registered Practitioner Organization, BRG will ensure that system development incorporates cybersecurity throughout the development lifecycle.\nCybersecurity engineers will be embedded within the Page 29 of 34",
        "37": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 software development team to ensure design and development activities are aligned with the Risk Management Framework (RMF).\nShould a government information system be desired, our security engineers will initiate the documents necessary for an Authority to Operate (ATO) in Phase II.\n10.\nSubcontractors/Consultants.\nNone 11.\nPrior, Current or Pending Support of Similar Proposals or Awards.\nNo prior, current, or pending support has been provided for proposed work.\n12.\nIdentification and Assertion of Restrictions on the Government\u2019s Use, Release, or Disclosure of Technical Data or Computer Software.\nNone Page 30 of 34",
        "38": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 References Aditya, S., Yang, Y., & Baral, C.\n(2019, August).\nIntegrating Knowledge and Reasoning in Image Understanding.\nIn Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence.\nAditya, K.\nMukherji, S.\nBalasubramanian, A.\nChaudhary, P.\nShakarian, PyReason: Software for Open World Temporal Logic, AAAI Spring Symposium (Mar.\n2023).\nAlmukaynizi, E.\nNunes, K.\nDharaiya, M.\nSenguttuvan, J.\nShakarian, P.\nShakarian, Proactive Identification of Exploits in the Wild Through Vulnerability Mentions Online, 2017 IEEE International Conference on Cyber Conflict (CyCon-US) (Nov.\n2017).\nBavikadi, N.\nLee, P.\nShakarian, C.\nParvis, Sea-cret Agents: Maritime Abduction for Region Generation to Expose Dark Vessel Trajectories, submitted (2024).\nBavikadi, D.\nAditya, D.\nParkar, P.\nShakarian, G.\nMueller, C.\nParvis, G.\nSimari, Geospatial Trajectory Generation via Efficient Abduction: Deployment for Independent Testing, 40th Intl.\nConference on Logic Programming (ICLP- 24).\nBollacker, K., Evans, C., Paritosh, P., Sturge, T., & Taylor, J.\n(2008, June).\nFreebase: a collaboratively created graph database for structuring human knowledge.\nIn Proceedings of the 2008 ACM SIGMOD international conference on Management of data (pp.\n1247-1250).\nChen, B., Lin, X., Thomas, C., Li, M., Yoshida, S., Chum, L., ...\n& Chang, S.\nF.\n(2021, November).\nJoint Multimedia Event Extraction from Video and Article.\nIn Findings of the Association for Computational Linguistics: EMNLP 2021 (pp.\n74-88).\nChen, L., Niu, Y., Chen, B., Lin, X., Han, G., Thomas, C., ...\n& Chang, S.\nF.\n(2022, December).\nWeakly-Supervised Temporal Article Grounding.\nIn Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (pp.\n9402-9413).\nChen, T.\nC., Tang, C.\nW., & Thomas, C.\n(2024, August).\nMetaSumPerceiver: Multimodal Multi-Document Evidence Summarization for Fact-Checking.\nIn Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp.\n8742-8757).\nChen, X., Zhang, N., Li, L., Deng, S., Tan, C., Xu, C., ...\n& Chen, H.\n(2022, July).\nHybrid transformer with multi-level fusion for multimodal knowledge graph completion.\nIn Proceedings of the 45th international ACM SIGIR conference on research and development in information retrieval (pp.\n904-915).\nChen, Z., Chen, J., Zhang, W., Guo, L., Fang, Y., Huang, Y., ...\n& Chen, H.\n(2023, October).\nMeaformer: Multi-modal entity alignment transformer for meta modality hybrid.\nIn Proceedings of the 31st ACM International Conference on Multimedia (pp.\n3317-3327).\nCheng, S., Zhang, N., Tian, B., Chen, X., Liu, Q., & Chen, H.\n(2024, March).\nEditing language model-based knowledge graph embeddings.\nIn Proceedings of the AAAI Conference on Artificial Intelligence (Vol.\n38, No.\n16, pp.\n17835- 17843).\nChu, Y., Xu, J., Zhou, X., Yang, Q., Zhang, S., Yan, Z., ...\n& Zhou, J.\n(2023).\nQwen-audio: Advancing universal audio understanding via unified large-scale audio-language models.\narXiv preprint arXiv:2311.07919.\nCurrin, G.\n(2023).\nWhen trust is a factor.\nColumbia Magazine.\nFrom https://topics.engineering.columbia.edu/when- trust-is-a-factor/ Ding, Y., Yu, J., Liu, B., Hu, Y., Cui, M., & Wu, Q.\n(2022).\nMuKEA: Multimodal Knowledge Extraction and Accumulation for Knowledge-based Visual Question Answering.\nIn Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp.\n5089-5098).\nDror, R., Wang, H., & Roth, D.\n(2023, May).\nZero-Shot On-the-Fly Event Schema Induction.\nIn Findings of the Association for Computational Linguistics: EACL 2023 (pp.\n705-725).\nDu, X., Zhang, Z., Li, S., Yu, P., Wang, H., Lai, T., ...\n& Ji, H.\n(2022, July).\nRESIN-11: Schema-guided event prediction for 11 newsworthy scenarios.\nIn Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: System Demonstrations (pp.\n54-63).\nDubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle, A., Letman, A., ...\n& Ganapathy, R.\n(2024).\nThe llama 3 herd of models.\narXiv preprint arXiv:2407.21783.\nFung, Y., Thomas, C., Reddy, R.\nG., Polisetty, S., Ji, H., Chang, S.\nF., ...\n& Sil, A.\n(2021, August).\nInfosurgeon: Cross- media fine-grained information consistency checking for fake news detection.\nIn Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) (pp.\n1683-1698).\nPage 31 of 34",
        "39": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 Fung, Y., Wang, H., Wang, T., Kebarighotbi, A., Bansal, M., Ji, H., & Natarajan, P.\n(2023, May).\nDeepMaven: Deep question answering on long-distance movie/TV show videos with multimedia knowledge extraction and synthesis.\nIn Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics (pp.\n3041-3051).\nGetoor, L., Friedman, N., Koller, D., Pfeffer, A., Taskar, B.\n(2007).\nProbabilistic relational models.\nIntroduction to statistical relational learning 8.\nGupta, S., Kenkre, S., & Talukdar, P.\n(2019, November).\nCare: Open knowledge graph embeddings.\nIn Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) (pp.\n378-388).\nHaider, S., Levis, A.H.\n(2008).\nModeling time-varying uncertain situations using dynamic influence nets.\nInternational Journal of Approximate Reasoning 49(2), 488\u2013502.\nHao, Y., Cao, P., Chen, Y., Liu, K., Xu, J., Li, H., ...\n& Zhao, J.\n(2023, December).\nComplex Event Schema Induction with Knowledge-Enriched Diffusion Model.\nIn Findings of the Association for Computational Linguistics: EMNLP 2023 (pp.\n4809-4825).\nHogan, A., Blomqvist, E., Cochez, M., d\u2019Amato, C., Melo, G.\nD., Gutierrez, C., ...\n& Zimmermann, A.\n(2021).\nKnowledge graphs.\nACM Computing Surveys (Csur), 54(4), 1-37.\nHoward, R.A., Matheson, J.E.\n(2005).\nInfluence diagrams.\nDecision Analysis 2(3),127\u2013143.\nIlievski, F., Garijo, D., Chalupsky, H., Divvala, N.\nT., Yao, Y., Rogers, C., ...\n& Szekely, P.\n(2020).\nKGTK: a toolkit for large knowledge graph manipulation and analysis.\nIn The Semantic Web\u2013ISWC 2020: 19th International Semantic Web Conference, Athens, Greece, November 2\u20136, 2020, Proceedings, Part II 19 (pp.\n278-293).\nSpringer International Publishing.\nJin, X., Li, M., & Ji, H.\n(2022, July).\nEvent schema induction with double graph autoencoders.\nIn Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (pp.\n2013-2025).\nKato, K., Li, Y., & Gupta, A.\n(2018).\nCompositional learning for human object interaction.\nIn Proceedings of the European Conference on Computer Vision (ECCV) (pp.\n234-251).\nKimmig, A., Bach, S., Broecheler, M., Huang, B., Getoor, L.\n(2012).\nA short introduction to probabilistic soft logic.\nIn: Proceedings of the NIPS workshop on probabilistic programming: foundations and applications.\npp.\n1\u20134.\nLi, M., Li, S., Wang, Z., Huang, L., Cho, K., Ji, H., ...\n& Voss, C.\n(2021, November).\nThe Future is not One-dimensional: Complex Event Schema Induction by Graph Modeling for Event Prediction.\nIn Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (pp.\n5203-5215).\nLi, Q., Chen, Z., Ji, C., Jiang, S., & Li, J.\n(2024).\nLLM-based Multi-Level Knowledge Generation for Few-shot Knowledge Graph Completion.\nIn Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intelligence (2024).\nhttps://api.\nsemanticscholar.\norg/CorpusID (Vol.\n271494703).\nLi, M., Zareian, A., Lin, Y., Pan, X., Whitehead, S., Chen, B., & Freedman, M.\n(2020, July).\nGaia: A fine-grained multimedia knowledge extraction system.\nIn Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations (pp.\n77-86).\nLi, M., Zareian, A., Zeng, Q., Whitehead, S., Lu, D., Ji, H., & Chang, S.\nF.\n(2020, July).\nCross-media Structured Common Space for Multimedia Event Extraction.\nIn Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (pp.\n2557-2568).\nLi, S., Zhao, R., Li, M., Ji, H., Callison-Burch, C., & Han, J.\n(2023, January).\nOpen-Domain Hierarchical Event Schema Induction by Incremental Prompting and Verification.\nIn Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Vol.\n1).\nLiang, W., Meo, P.\nD., Tang, Y., & Zhu, J.\n(2024).\nA survey of multi-modal knowledge graphs: Technologies and trends.\nACM Computing Surveys, 56(11), 1-41.\nLin, Q., Mao, R., Liu, J., Xu, F., & Cambria, E.\n(2023).\nFusing topology contexts and logical rules in language models for knowledge graph completion.\nInformation Fusion, 90, 253-264.\nLiu, Y., Zeng, Q., Ordieres Mer\u00e9, J., & Yang, H.\n(2019).\nAnticipating stock market of the renowned companies: A knowledge graph approach.\nComplexity, 2019.\nMa, Y., Wang, Z., Li, M., Cao, Y., Chen, M., Li, X., ...\n& Shao, J.\n(2022).\nMMEKG: Multi-modal event knowledge graph towards universal representation across modalities.\nAssociation for Computational Linguistics.\nPage 32 of 34",
        "40": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 Marino, K., Salakhutdinov, R., & Gupta, A.\n(2017).\nThe More You Know: Using Knowledge Graphs for Image Classification.\nIn Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp.\n2673- 2681).\nMausam, M.\n(2016, July).\nOpen information extraction systems and downstream applications.\nIn Proceedings of the twenty-fifth international joint conference on artificial intelligence (pp.\n4074-4077).\nMarkets & Markets.\n(2024).\nKnowledge graph market.\nhttps://www.marketsandmarkets.com/Market- Reports/knowledge-graph-market-217920811.html Nguyen, K.\nD., Zhang, Z., Suchocki, R., Li, S., Palmer, M., Brown, S., ...\n& Ji, H.\n(2023).\nRESIN-EDITOR: A Schema- guided Hierarchical Event Graph Visualizer and Editor.\nIn 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023.\nOwler.\n(2024).\nTellius competitors and alternatives.\nhttps://www.owler.com/company/tellius/competitors Pearl, J.\n(1988).\nProbabilistic reasoning in intelligent systems: networks of plausible inference.\nMorgan Kaufmann.\nPersistence Market Research.\n(2023).\nBusiness intelligence platform market.\nhttps://www.persistencemarketresearch.com/market-research/business-intelligence-platform-market.asp Radford, A., Kim, J.\nW., Xu, T., Brockman, G., McLeavey, C., & Sutskever, I.\n(2023, July).\nRobust speech recognition via large-scale weak supervision.\nIn International conference on machine learning (pp.\n28492-28518).\nPMLR.\nRajabi, E., & Etminani, K.\n(2024).\nKnowledge-graph-based explainable AI: A systematic review.\nJournal of Information Science, 50(4), 1019-1029.\nRichardson, M., Domingos, P.\n(2006).\nMarkov logic networks.\nMachine learning 62, 107\u2013 136 (2006).\nAlmukaynizi, J.\nShakarian, P.\nShakarian, Mining user interaction patterns in the darkweb to predict enterprise cyber incidents, Social Network Analysis and Mining, 9(1), 2019.\nSeo, S., Oh, B., Jo, E., Lee, S., Lee, D., Lee, K.\nH., ...\n& Lee, Y.\n(2021).\nActive learning for knowledge graph schema expansion.\nIEEE Transactions on Knowledge and Data Engineering, 34(12), 5610-5620.\nShakarian, G.I.\nSimari, Extensions to Generalized Annotated Logic and an Equivalent Neural Architecture, IEEE TransAI, 2022.\nShen, T., Zhang, F., & Cheng, J.\n(2022).\nA comprehensive overview of knowledge graph completion.\nKnowledge- Based Systems, 255, 109597.\nSubagdja, B., Shanthoshigaa, D., Wang, Z., & Tan, A.\nH.\n(2024).\nMachine Learning for Refining Knowledge Graphs: A Survey.\nACM Computing Surveys, 56(6), 1-38.\nTang, C.-W., Chen, T.-C., Ishmam, A.\nM., Nguyen, K.\nA., Mehrab, K.\nS., & Thomas, C.\n(2024).\nM3D: MultiModal MultiDocument Fine-Grained Inconsistency Detection.\nTo appear, In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing.\nLong papers.\nThomas, C., Zhang, Y., & Chang, S.\nF.\n(2022, October).\nFine-grained visual entailment.\nIn European Conference on Computer Vision (pp.\n398-416).\nCham: Springer Nature Switzerland.\nU.S.\nDepartment of Homeland Security.\n(2024).\nCritical infrastructure.\nhttps://www.dhs.gov/archive/science-and- technology/critical-infrastructure U.S.\nDepartment of Defense.\n(2023, March).\nDepartment of Defense releases the President's fiscal year 2024 defense budget.\nhttps://www.defense.gov/news/releases/release/article/3326875/department-of-defense- releases-the-presidents-fiscal-year-2024-defense-budget/ Vrande\u010di\u0107, D., & Kr\u00f6tzsch, M.\n(2014).\nWikidata: a free collaborative knowledgebase.\nCommunications of the ACM, 57(10), 78-85.\nWang, C., Zhou, X., Pan, S., Dong, L., Song, Z., & Sha, Y.\n(2022, June).\nExploring relational semantics for inductive knowledge graph completion.\nIn Proceedings of the AAAI Conference on Artificial Intelligence (Vol.\n36, No.\n4, pp.\n4184-4192).\nWang, D., Tang, K., Zeng, J., Pan, Y., Dai, Y., Li, H., & Han, B.\n(2024).\nMM-Transformer: A Transformer-Based Knowledge Graph Link Prediction Model That Fuses Multimodal Features.\nSymmetry, 16(8), 961.\nWang, H., Zhang, Z., Li, S., Han, J., Sun, Y., Tong, H., Olive, J.\nP., & Ji, H.\n(2022).\nProceedings of the 4th Conference on Automated Knowledge Base Construction (AKBC 2022).\nWang, Q., & Li, M.\n(2021, June).\nCOVID-19 Literature Knowledge Graph Construction and Drug Repurposing Report Generation.\nIn Proc.\nThe 2021 Conference of the North American Chapter of the Association for Computational Linguistics-Human Language Technologies (NAACL-HLT2021) Demo Track.\nWen, H., Lin, Y., Lai, T., Pan, X., Li, S., Lin, X., ...\n& Ji, H.\n(2021, June).\nResin: A dockerized schema-guided cross- document cross-lingual cross-media information extraction and event tracking system.\nIn Proceedings of the Page 33 of 34",
        "41": "Proposer: The Bulls Run Group Proposal Number: F244-0001-0048 \u2013 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis Topic Number AF244-0001 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations (pp.\n133-143).\nWilcke, W.\nX., Bloem, P., de Boer, V., & van t Veer, R.\nH.\n(2023).\nEnd-to-end learning on multimodal knowledge graphs.\narXiv preprint arXiv:2309.01169.\nWu, X., Huang, K.\nH., Fung, Y., & Ji, H.\n(2022, July).\nCross-document misinformation detection based on event graph reasoning.\nIn Proceedings of the 2022 conference of the north american chapter of the association for computational linguistics: Human language technologies (pp.\n543-558).\nYang, A., Yang, B., Hui, B., Zheng, B., Yu, B., Zhou, C., Li, C., Li, C., Liu, D., Huang, F., & others.\n(2024).\nQwen2 technical report.\narXiv Preprint arXiv:2407.10671.\nYe, J., Xu, H., Liu, H., Hu, A., Yan, M., Qian, Q., ...\n& Zhou, J.\n(2024).\nmplug-owl3: Towards long image-sequence understanding in multi-modal large language models.\narXiv preprint arXiv:2408.04840.\nZhang, M., Xia, Y., Liu, Q., Wu, S., & Wang, L.\n(2023, July).\nLearning latent relations for temporal knowledge graph reasoning.\nIn Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp.\n12617-12631).\nconstruction.\nACM Computing Surveys, 56(4), 1-62.\nZhang, T., Tham, I., Hou, Z., Ren, J., Zhou, L., Xu, H., ...\n& Callison-Burch, C.\n(2023).\nHuman-in-The-loop schema induction.\nIn 61st Annual Meeting of the Association for Computational Linguistics, ACL-DEMO 2023 (pp.\n1- 10).\nAssociation for Computational Linguistics (ACL).\nZhang, T., Tham, I., Hou, Z., Ren, J., Zhou, L., Xu, H., ...\n& Callison-Burch, C.\n(2023, July).\nHuman-in-the-loop Schema Induction.\nIn The 61st Annual Meeting Of The Association For Computational Linguistics.\nZhang, X., Liang, X., Zheng, X., Wu, B., & Guo, Y.\n(2022, September).\nMULTIFORM: few-shot knowledge graph completion via multi-modal contexts.\nIn Joint European Conference on Machine Learning and Knowledge Discovery in Databases (pp.\n172-187).\nCham: Springer International Publishing.\nZhang, Z., Zhuang, F., Qu, M., Lin, F., & He, Q.\n(2018).\nKnowledge graph embedding with hierarchical relation structure.\nIn Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (pp.\n3198-3207).\nZhong, L., Wu, J., Li, Q., Peng, H., & Wu, X.\n(2023).\nA comprehensive survey on automatic knowledge graph Page 34 of 34",
        "42": "SBIR Phase I Proposal Proposal Number Topic Number Proposal Title Date Submitted Firm Information Firm Name Mail Address Website Address UEI Duns Cage F244-0001-0048 AF244-0001 IKOS: Interactive Knowledge Graphs for Open-Source Intelligence Analysis 11/05/2024 05:16:50 PM The Bulls Run Group, Inc 9207 Bulls Run Pkwy, Bethesda, Maryland, 20817 https://www.bulls.run KDH9SC281WL8 129524731 8LSH4 Total Dollar Amount for this Proposal Base Year Year 2 Technical and Business Assistance(TABA)- Base TABA- Year 2 Base Year Summary Total Direct Labor (TDL) Total Direct Material Costs (TDM) Total Direct Supplies Costs (TDS) Total Direct Equipment Costs (TDE) Total Direct Travel Costs (TDT) Total Other Direct Costs (TODC) G&A (rate 15%) x Base (TDL+TOH+TDT) Total Firm Costs Subcontractor Costs Total Subcontractor Costs (TSC) Cost Sharing Profit Rate (10%) Total Estimated Cost TABA Year 2 Summary Total Direct Labor (TDL) Total Direct Material Costs (TDM) $139,992.88 $139,992.88 $0.00 $0.00 $0.00 $108,453.31 $0.00 $0.00 $0.00 $2,213.00 $0.00 $16,599.95 $127,266.26 $0.00 -$0.00 $12,726.63 $139,992.88 $0.00 $0.00 $0.00",
        "43": "Total Direct Supplies Costs (TDS) Total Direct Equipment Costs (TDE) Total Direct Travel Costs (TDT) Total Other Direct Costs (TODC) G&A (rate 15%) x Base (TDL+TOH+TDT) Total Firm Costs Subcontractor Costs Total Subcontractor Costs (TSC) Cost Sharing Profit Rate (10%) Total Estimated Cost TABA Base Year Direct Labor Costs $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 -$0.00 $0.00 $0.00 $0.00 Category / Individual-TR Chief Executive/ Principal Investigator (Stoney Trent) Computer and Information Research Scientist/ coPI (Chris Thomas) Computer and Information Research Scientist/ Senior Computer Scientist (Paulo Shakarian) Computer and Information Research Scientist/ Senior Computer Scientist (Amy Sliva) Rate/Hour Estimated Hours Fringe Rate (%) Fringe Cost Cost $240.00 90 0 $0.00 $21,600.00 $150.00 90 $13,500.00 $150.00 70 $10,500.00 $150.00 70 $10,500.00 General and Operations Manager/ Project Manager/ Intel SME (James Doty) $81.73 80 15 24 $980.76 $7,519.16 $1752.00 $9,052.00 $91.25 80 Computer and Information Research Scientist/ Senior UX Researcher (Brandon Beltz) Software Developer/ System Architect/ Software Engineer (Van Truong) Computer and Information Research Scientist/ Software Developer Subtotal Direct Labor (DL) Labor Overhead (rate 20%) x (DL) Total Direct Labor (TDL) $89.09 43 38 $1455.73 $5,286.60 $45.00 240 15 $1620.00 $12,420.00 $90,377.76 $18,075.55 $108,453.31",
        "44": "Direct Travel Costs Project kickoff Total Direct Travel Costs (TDT) G&A (rate 15%) x Base (TDL+TOH+TDT) Cost Sharing Profit Rate (10%) Total Estimated Cost TABA Year 2 Direct Labor Costs $2,213.00 $2,213.00 $16,599.95 -$0.00 $12,726.63 $139,992.88 $0.00 Category / Individual-TR Rate/Hour Estimated Hours Fringe Rate (%) Fringe Cost Cost Chief Executive/ Principal Investigator (Stoney Trent) $250.00 0 Subtotal Direct Labor (DL) Labor Overhead (rate 20%) x (DL) Total Direct Labor (TDL) Direct Travel Costs none Total Direct Travel Costs (TDT) G&A (rate 15%) x Base (TDL+TOH+TDT) Cost Sharing Profit Rate (10%) Total Estimated Cost TABA $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 -$0.00 $0.00 $0.00 $0.00 Explanatory Material Relating to the Cost Volume The Official From the Firm that is responsible for the cost breakdown Name: Stoney Trent Phone: (301) 456-4237 Phone: stoney@bullsrungroup.com Title: Proposal Owner If the Defence Contracting Audit Agency has performed a review of your projects within the past 12 months, please provide: No Select the Type of Payment Desired: Partial payments",
        "45": "Cost Volume Details Direct Labor Base Category Description Education Yrs Experience Hours Rate Fringe Rate Total Chief Executive Principal Investigator PhD Computer and Information Research Scientist coPI Computer and Information Research Scientist Computer and Information Research Scientist Senior Computer Scientist Senior Computer Scientist PhD PhD PhD General and Operations Manager Project Manager/ Intel SME PhD Computer and Information Research Scientist Senior UX Researcher PhD Software Developer System Architect/ Software Engineer Master's Degree Computer and Information Research Scientist Software Developer Master's Degree 15 10 15 15 25 20 20 2 90 90 $240.00 0 $21,600.00 $150.00 $13,500.00 70 $150.00 $10,500.00 70 $150.00 $10,500.00 80 $81.73 15 $7,519.16 80 $91.25 24 $9,052.00 43 $89.09 38 $5,286.60 240 $45.00 15 $12,420.00 Are the labor rates detailed below fully loaded?\nNO Provide any additional information and cost support data related to the nature of the direct labor detailed above.\nDr.\nTrent is the Owner, President, and CEO of The Bulls Run Group.\nDr.\nTrent is a uniquely skilled researcher with 25+ years of relevant operational expertise.\nLabor rate Documentation: \u2022 Trent rate justification.docx",
        "46": "Direct Labor Cost ($): Year2 $90,377.76 Category Description Education Yrs Experience Hours Rate Fringe Rate Total Chief Executive Principal Investigator PhD 15 0 $250.00 $0.00 Are the labor rates detailed below fully loaded?\nYES Please explain any costs that apply.\nThere are no costs proposed in Year 2 because this is a 6 month proposal.\nProvide any additional information and cost support data related to the nature of the direct labor detailed above.\nNA Direct Labor Cost ($): Sum of all Direct Labor Costs is($): Overhead Base Labor Cost Overhead Rate (%) Apply Overhead to Direct Travel Cost?\nOverhead Comments: IT equipment, software, internet, training, legal and contracting, office expenses Overhead Cost ($): Year2 Labor Cost Overhead Rate (%) Apply Overhead to Direct Travel Cost?\nOverhead Comments: Overhead Cost ($): $0.00 $90,377.76 20 NO $18,075.55 20 NO $0.00",
        "47": "Sum of all Overhead Costs is ($): General and Administration Cost Base G&A Rate (%): Apply G&A Rate to Overhead Costs?\nApply G&A Rate to Direct Labor Costs?\nApply G&A Rate to ODC- Travel?\nPlease specify the different cost sources below from which your company's General and Administrative costs are calculated.\nBusiness development, finance, contract administration, insurance, certifications, accounting software, wireless data plans, collaboration software, HR management system, advertising and marketing, tax preparation, video conferencing, IT equipment G&A Cost ($): Year2 G&A Rate (%): Apply G&A Rate to Overhead Costs?\nApply G&A Rate to Direct Labor Costs?\nApply G&A Rate to ODC- Travel?\nPlease specify the different cost sources below from which your company's General and Administrative costs are calculated.\nG&A Cost ($): Sum of all G&A Costs is ($): ODC-Travel Base Description: Project kickoff Location From: Blacksburg, VA Location To: Arlington, VA $18,075.55 15 YES YES YES $16,599.95 15 YES YES YES $0.00 $16,599.95",
        "48": "Number of People: 3 Number of Days: 1 Purpose of Trip: Project Kickoff meeting Total Airfare Costs ($): $0.00 Total Car Rental Costs ($): $0.00 Total Per Diem Costs ($): $1,138.00 Total Other Costs ($): $1,075.00 Total Costs ($): $2,213.00 Purpose of Trip: Project Kickoff meeting Sources of Estimates: GSA per diem and mileage rates Explanation/Justifications: 3 key persons driving in POV for kickoff meeting Year2 Description: none Location From: NA Number of People: 0 Purpose of Trip: NA Location To: NA Number of Days: 0 Total Airfare Costs ($): $0.00 Total Car Rental Costs ($): $0.00 Total Per Diem Costs ($): $0.00 Total Other Costs ($): $0.00 Total Costs ($): $0.00 Purpose of Trip: NA Sources of Estimates: NA Explanation/Justifications: NA ODC-Summary Base Do you have any additional information to provide?\nYear2 Do you have any additional information to provide?\nProfit Rate/Cost Sharing NO NO",
        "49": "Base Cost Sharing ($): Cost Sharing Explanation: Profit Rate (%): Profit Explanation: Total Profit Cost ($): Year2 Cost Sharing ($): Cost Sharing Explanation: Profit Rate (%): Profit Explanation: Total Profit Cost ($): Total Proposed Amount ($): - 10 $12,726.63 - 10 $12,726.63 $139,992.88",
        "50": "SBIR Company Commercialization Report BULLS RUN GROUP, LLC, THE DISCLAIMER: Information provided herein is privileged and confidential, and not subject to disclosure, pursuant to 15 U.S.C.\n638 (k)(4) and 5 U.S.C.\n552.\nThis information shall only be used or disclosed for evaluation purposes.\nPrivileged and confidential and not subject to disclosure pursuant to 15 U.S.C.\n638 (k)(4) and 5 U.S.C.\n552.\nLast Updated on: 10/03/2024 Page 1",
        "51": "SBIR Company Commercialization Report Total Investments: $250,000.00 Total Sales: $2,000,000.00 Total Patents: 0 Government Designated Phase III Funding: $0.00 Company Information Address: 9207 BULLS RUN PKWY, BETHESDA, MD 20817-2403 SBC Control ID: SBC_001972933 Company URL: https://www.bulls.run/ Additional Company Information % Revenue for last fiscal year from SBIR/STTR funding: 0% Year Founded: 2020 Total revenue for last fiscal year: $100,000 - $499,999 # Employees Currently: 10 Year first Phase I award received: # SBIR/STTR Phase I Awards: N/A N/A Year first Phase II award received: # SBIR/STTR Phase II Awards: N/A N/A # Employees at first Phase II award: Mergers and Acquisition within past 2 years: N/A No Spin-offs resulting from SBIR/STTR: IPO resulting from SBIR/STTR | Year of IPO: No Patents resulting from SBIR/STTR | #Patents: No List of Patents: No Woman-Owned: No HUBZone-Certified: Yes Additional Investment From DoD contracts/DoD subcontracts Angel Investors Venture Capital Self Funded Private Sector Other Federal Contracts/Grants Other Sources Socially and Economically Disadvantaged: No SBC majority-owned by multiple VCOC, HF, PE firms | By what percent (%): No Last Submitted Version (2021-05-10 09:48:09) Current Version $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 Privileged and confidential and not subject to disclosure pursuant to 15 U.S.C.\n638 (k)(4) and 5 U.S.C.\n552.\nLast Updated on: 10/03/2024 Page 2",
        "52": "SBIR Company Commercialization Report Additional Investment Total Investment Phase III Sales To DoD or DoD prime contractors Private Sector Export Markets Other Federal Agencies Additional commercialization by 3rd Party Revenue Other Customers Additional Sales Total Sales Government Phase III Contracts Funding Obligated Commercialization Narrative Commercialized Awards $0.00 $0.00 $0.00 $0.00 Last Submitted Version (2021-05-10 09:48:09) Current Version $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 $0.00 Last Submitted Version (2021-05-10 09:48:09) $0.00 Current Version $0.00 Listed below are the sales revenue and investment details resulting from the technology developed under these SBIR/STTR awards.\nPrivileged and confidential and not subject to disclosure pursuant to 15 U.S.C.\n638 (k)(4) and 5 U.S.C.\n552.\nLast Updated on: 10/03/2024 Page 3",
        "53": "Stoney Trent, The Bulls Run Group, Inc Oct 11, 2024 Oct 11, 2025"
    },
    "images": [
        {
            "page": 10,
            "image_file": "docNAC01FB7453535f20dd5d3e434380aea996b91e95b0ab1730760eee36fd178dc0180453cf2b0f_page10_img1.png",
            "hash": "f3946b3ae8634469",
            "position": "Middle Center"
        },
        {
            "page": 12,
            "image_file": "docNAC01FB7453535f20dd5d3e434380aea996b91e95b0ab1730760eee36fd178dc0180453cf2b0f_page12_img1.jpeg",
            "hash": "970640b09fcbf879",
            "position": "Middle Center"
        },
        {
            "page": 13,
            "image_file": "docNAC01FB7453535f20dd5d3e434380aea996b91e95b0ab1730760eee36fd178dc0180453cf2b0f_page13_img1.jpeg",
            "hash": "ca924a974ca96d6b",
            "position": "Top Center"
        },
        {
            "page": 13,
            "image_file": "docNAC01FB7453535f20dd5d3e434380aea996b91e95b0ab1730760eee36fd178dc0180453cf2b0f_page13_img2.jpeg",
            "hash": "83f7495eb0aab509",
            "position": "Bottom Center"
        },
        {
            "page": 14,
            "image_file": "docNAC01FB7453535f20dd5d3e434380aea996b91e95b0ab1730760eee36fd178dc0180453cf2b0f_page14_img1.png",
            "hash": "bf8c8863e1c0d676",
            "position": "Middle Center"
        },
        {
            "page": 16,
            "image_file": "docNAC01FB7453535f20dd5d3e434380aea996b91e95b0ab1730760eee36fd178dc0180453cf2b0f_page16_img1.jpeg",
            "hash": "b6b64959a16349bc",
            "position": "Top Center"
        },
        {
            "page": 17,
            "image_file": "docNAC01FB7453535f20dd5d3e434380aea996b91e95b0ab1730760eee36fd178dc0180453cf2b0f_page17_img1.jpeg",
            "hash": "e76849269d89b0be",
            "position": "Top Center"
        },
        {
            "page": 19,
            "image_file": "docNAC01FB7453535f20dd5d3e434380aea996b91e95b0ab1730760eee36fd178dc0180453cf2b0f_page19_img1.png",
            "hash": "9ee09be2e266d261",
            "position": "Middle Center"
        },
        {
            "page": 21,
            "image_file": "docNAC01FB7453535f20dd5d3e434380aea996b91e95b0ab1730760eee36fd178dc0180453cf2b0f_page21_img1.png",
            "hash": "be36e4e7e5065230",
            "position": "Middle Center"
        },
        {
            "page": 22,
            "image_file": "docNAC01FB7453535f20dd5d3e434380aea996b91e95b0ab1730760eee36fd178dc0180453cf2b0f_page22_img1.png",
            "hash": "d2a4b4a50fd2587d",
            "position": "Top Center"
        },
        {
            "page": 23,
            "image_file": "docNAC01FB7453535f20dd5d3e434380aea996b91e95b0ab1730760eee36fd178dc0180453cf2b0f_page23_img1.png",
            "hash": "8701f8fcf0fa030f",
            "position": "Top Center"
        },
        {
            "page": 25,
            "image_file": "docNAC01FB7453535f20dd5d3e434380aea996b91e95b0ab1730760eee36fd178dc0180453cf2b0f_page25_img1.png",
            "hash": "ea66954a999d9391",
            "position": "Middle Center"
        },
        {
            "page": 26,
            "image_file": "docNAC01FB7453535f20dd5d3e434380aea996b91e95b0ab1730760eee36fd178dc0180453cf2b0f_page26_img1.jpeg",
            "hash": "815b9222f3fe4d43",
            "position": "Middle Center"
        },
        {
            "page": 32,
            "image_file": "docNAC01FB7453535f20dd5d3e434380aea996b91e95b0ab1730760eee36fd178dc0180453cf2b0f_page32_img1.png",
            "hash": "eb37eca02c13f0d2",
            "position": "Middle Left"
        },
        {
            "page": 50,
            "image_file": "docNAC01FB7453535f20dd5d3e434380aea996b91e95b0ab1730760eee36fd178dc0180453cf2b0f_page50_img1.png",
            "hash": "af138d9df060536a",
            "position": "Top Left"
        },
        {
            "page": 51,
            "image_file": "docNAC01FB7453535f20dd5d3e434380aea996b91e95b0ab1730760eee36fd178dc0180453cf2b0f_page51_img1.png",
            "hash": "af138d9df060536a",
            "position": "Top Left"
        },
        {
            "page": 52,
            "image_file": "docNAC01FB7453535f20dd5d3e434380aea996b91e95b0ab1730760eee36fd178dc0180453cf2b0f_page52_img1.png",
            "hash": "af138d9df060536a",
            "position": "Top Left"
        }
    ],
    "firm_info": {
        "company": "N/A",
        "address": "N/A",
        "website": "bulls.run",
        "name": "N/A",
        "phone": "N/A"
    }
}